<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis实现分布式环境的限流]]></title>
    <url>%2F2018%2F05%2F11%2FRedis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E7%9A%84%E9%99%90%E6%B5%81%2F</url>
    <content type="text"><![CDATA[分布式系统中，当流量瞬间飙升，而系统本身无法承载过多的请求时，可能造成的后果就是系统的雪崩，在实际工作中，往往都会用到必要的限流手段来处理。 常见的限流措施 通过限制单位时间段内调用量来限流（计数器）：计算单位时间段内请求的次数，达到约定阈值，则拒绝 使用漏桶（Leaky Bucket）算法来进行限流：两端流通，一遍在消费，一遍在生产，如果生产的速率大于消费的速率，而且达到桶的总容量，则等待 使用令牌桶（Token Bucket）算法来进行限流:按固定速率往桶里面放固定数量的令牌 单节点限流Google的guava项目中，有个RateLimiter类实现单节点限流，如下1234567891011121314/** * RateLimiter限制线程数 */ public static void testRateLimiter() &#123; ExecutorService executorService = Executors.newFixedThreadPool(100); RateLimiter limiter = RateLimiter.create(10.0); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 100; i++) &#123; limiter.acquire(); executorService.execute(new Task("is " + i)); &#125; long end = System.currentTimeMillis(); System.out.println("总共耗时：" + (end - start) + "ms"); &#125; 创建一个限流实例，指定每秒限制的线程数，在使用的时候，加上limiter.acquire()就ok了，非常简单。 Redis实现分布式计数器限流 RateLimiter实现了单节点的限流，那么如何实现多节点的总体限流呢，这时候我们需要借助Redis了，用Redis当一个集中的计数器，所有的节点共用同一个计数器。 我们做一个简单的封装，把限流器定义成一个注解，然后定义2个属性，时间和次数，这也是计数器的2个核心属性。 123456789101112131415161718192021222324252627282930package com.smart.server.ratelimit.annotation;import org.springframework.core.Ordered;import org.springframework.core.annotation.Order;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * 通用的方法限流 */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Documented@Order(Ordered.HIGHEST_PRECEDENCE)public @interface SmartRateLimit &#123; /** * 允许访问的次数，默认值MAX_VALUE */ long limitCount() default Long.MAX_VALUE; /** * 时间段，单位秒,默认每秒限流大小 */ long timeRange() default 1;&#125; 注解的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.smart.server.ratelimit.interceptor;import com.smart.server.ratelimit.RequestLimitException;import com.smart.server.ratelimit.annotation.SmartRateLimit;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.aop.support.AopUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.EnableAspectJAutoProxy;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Component;import java.lang.reflect.Method;import java.util.concurrent.TimeUnit;import lombok.extern.slf4j.Slf4j;/** * @author gaowenming * @create 2018-05-10 14:56 * @desc 通用方法限流实现 **/@Aspect@Component@EnableAspectJAutoProxy(proxyTargetClass = true)@Slf4jpublic class SmartRateLimitInterceptor &#123; @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; @Pointcut("@annotation(com.smart.server.ratelimit.annotation.SmartRateLimit)") private void limit() &#123; &#125; @Before("limit()") public void before(JoinPoint joinPoint) throws RequestLimitException &#123; MethodSignature methodSignature = (MethodSignature) joinPoint.getSignature(); Method targetMethod = AopUtils.getMostSpecificMethod(methodSignature.getMethod(), joinPoint.getTarget().getClass()); String targetName = joinPoint.getTarget().getClass().getName(); String methodName = joinPoint.getSignature().getName(); SmartRateLimit smartRateLimit = targetMethod.getAnnotation(SmartRateLimit.class); long limitCount = smartRateLimit.limitCount(); long timeRange = smartRateLimit.timeRange(); String redisKey = getRedisKey(targetName, methodName); long count = redisTemplate.opsForValue().increment(redisKey, 1); log.info("count:" + count); if (count == 1) &#123; redisTemplate.expire(redisKey, timeRange, TimeUnit.SECONDS); &#125; if (count &gt; limitCount) &#123; log.error("访问方法" + redisKey + "]超过了限定的次数[" + limitCount + "]"); throw new RequestLimitException("请求超出限制：" + redisKey + ", 当前次数：" + count); &#125; &#125; /** * 获取缓存的key值 */ private String getRedisKey(String targetName, String methodName) &#123; StringBuilder sb = new StringBuilder(""); sb.append("limitrate.").append(targetName).append(".").append(methodName); return sb.toString(); &#125;&#125; 利用Redis的increment自增操作记录单位时间内的请求数，Redis的单线程和increment的原子操作能够做到多线程下计数的准确性 当超过我们设计的阈值时，我们抛出一个超限异常，然后使用全局异常进行拦截处理 1234567891011121314151617package com.smart.server.ratelimit;/** * */public class RequestLimitException extends Exception &#123; private static final long serialVersionUID = 1364225358754654702L; public RequestLimitException() &#123; super("请求超出设定的限制"); &#125; public RequestLimitException(String message) &#123; super(message); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.smart.server.handler;import com.smart.server.base.BaseJsonResult;import com.smart.server.ratelimit.RequestLimitException;import com.smart.service.base.BusinessErrorMsg;import com.smart.service.base.BusinessException;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.bind.annotation.RestControllerAdvice;import java.util.Arrays;import java.util.Map;import javax.servlet.http.HttpServletRequest;import lombok.extern.slf4j.Slf4j;/** * 全局异常处理 * * 2017年4月28日 下午10:14:26 &lt;br/&gt; * * author gaowenming version since JDK 1.8 */@RestControllerAdvice@Slf4jpublic class GlobalExceptionHandler &#123; /** * 限流异常 */ @ExceptionHandler(value = RequestLimitException.class) @ResponseBody public BaseJsonResult&lt;Object&gt; limitExceptionHandler(HttpServletRequest req, Exception e) throws Exception &#123; printMethodParameters(req); BaseJsonResult&lt;Object&gt; baseJsonResult = new BaseJsonResult&lt;&gt;(); baseJsonResult.setStatus(HttpStatus.INTERNAL_SERVER_ERROR.value()); baseJsonResult.setMsg("系统繁忙,请稍后重试！"); return baseJsonResult; &#125;&#125; 至此，限流的处理已经完成，我们只需要在方法上加上注解即可 1234567@RequestMapping(value = "ratelimit", method = RequestMethod.GET)@SmartRateLimit(limitCount = 5)public BaseJsonResult rateLimit() throws Exception &#123; log.info("*********************************"); return successNullDataResult();&#125; 测试效果如下 018-05-11 15:32:26,379 INFO traceId=a1357c84974a40edab372684a662f097 [http-nio-8000-exec-8] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:12018-05-11 15:32:26,387 INFO traceId=a1357c84974a40edab372684a662f097 [http-nio-8000-exec-8] com.smart.server.controller.TestController-[47] *2018-05-11 15:32:26,840 INFO traceId=eb1c10450f54440f942b6b7b7e0ac555 [http-nio-8000-exec-9] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:22018-05-11 15:32:26,842 INFO traceId=eb1c10450f54440f942b6b7b7e0ac555 [http-nio-8000-exec-9] com.smart.server.controller.TestController-[47] *2018-05-11 15:32:26,882 INFO traceId=60e2b52b0d694bd2b705f5651a729d19 [http-nio-8000-exec-10] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:32018-05-11 15:32:26,883 INFO traceId=60e2b52b0d694bd2b705f5651a729d19 [http-nio-8000-exec-10] com.smart.server.controller.TestController-[47] *2018-05-11 15:32:26,912 INFO traceId=427f0c0e83484fec9a0f94d5411bdddf [http-nio-8000-exec-2] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:42018-05-11 15:32:26,913 INFO traceId=427f0c0e83484fec9a0f94d5411bdddf [http-nio-8000-exec-2] com.smart.server.controller.TestController-[47] *2018-05-11 15:32:26,932 INFO traceId=0082f7476b0f491199fc19fb7236cfae [http-nio-8000-exec-1] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:52018-05-11 15:32:26,933 INFO traceId=0082f7476b0f491199fc19fb7236cfae [http-nio-8000-exec-1] com.smart.server.controller.TestController-[47] *2018-05-11 15:32:26,957 INFO traceId=92c57baa8fa041a4ad611089945f50e3 [http-nio-8000-exec-4] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:62018-05-11 15:32:26,958 ERROR traceId=92c57baa8fa041a4ad611089945f50e3 [http-nio-8000-exec-4] c.s.s.r.interceptor.SmartRateLimitInterceptor-[59] 访问方法limitrate.com.smart.server.controller.TestController.rateLimit]超过了限定的次数[5]2018-05-11 15:32:26,979 INFO traceId=b1da1f21cac243919e0eeec638c99399 [http-nio-8000-exec-3] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:72018-05-11 15:32:26,980 ERROR traceId=b1da1f21cac243919e0eeec638c99399 [http-nio-8000-exec-3] c.s.s.r.interceptor.SmartRateLimitInterceptor-[59] 访问方法limitrate.com.smart.server.controller.TestController.rateLimit]超过了限定的次数[5]2018-05-11 15:32:27,011 INFO traceId=f3c64e4933944916b68134b1385dc66f [http-nio-8000-exec-5] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:82018-05-11 15:32:27,012 ERROR traceId=f3c64e4933944916b68134b1385dc66f [http-nio-8000-exec-5] c.s.s.r.interceptor.SmartRateLimitInterceptor-[59] 访问方法limitrate.com.smart.server.controller.TestController.rateLimit]超过了限定的次数[5]2018-05-11 15:32:27,045 INFO traceId=50848168f83e4b548ec4f0c9c476d01a [http-nio-8000-exec-6] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:92018-05-11 15:32:27,046 ERROR traceId=50848168f83e4b548ec4f0c9c476d01a [http-nio-8000-exec-6] c.s.s.r.interceptor.SmartRateLimitInterceptor-[59] 访问方法limitrate.com.smart.server.controller.TestController.rateLimit]超过了限定的次数[5]2018-05-11 15:32:27,093 INFO traceId=1fa4affb473c43f1998e2a0019e4d0fb [http-nio-8000-exec-7] c.s.s.r.interceptor.SmartRateLimitInterceptor-[54] count:10]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis实现分布式锁]]></title>
    <url>%2F2018%2F05%2F09%2FRedis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁在系统中使用的场景非常多，比如电商中的秒杀，定时任务的单节点执行都用到锁，而在分布式系统中，单纯的java自身支持的锁已经无法满足业务了，这时候就需要用到分布式锁了。 当前主流的实现方式 分布式锁，当前主要是3种主流的实现方式1、数据库的乐观锁，使用version的方式2、Zookeeper，主要利用zk的tmp节点的特性3、Redis，使用redis的setnx机制获取锁 Redis SETNX实现 SETNX命令（SET if Not eXists）语法：SETNX key value功能：原子性操作，当且仅当 key 不存在，将 key 的值设为 value ，并返回1；若给定的 key 已经存在，则 SETNX 不做任何动作，并返回0。 ##注意事项 使用SETNX和expire实现锁的时候，一定要保证谁拿到的锁，谁去释放锁，不能出现已经过期的锁，释放了别人持有的锁，这里使用lua脚本来实现，而不是使用del key的方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279package com.smart.server.lock;import org.springframework.dao.DataAccessException;import org.springframework.data.redis.connection.RedisConnection;import org.springframework.data.redis.core.RedisCallback;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.util.Assert;import org.springframework.util.StringUtils;import java.util.ArrayList;import java.util.List;import java.util.Random;import java.util.UUID;import lombok.extern.slf4j.Slf4j;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisCluster;import redis.clients.jedis.JedisCommands;/** * Redis分布式锁 使用 SET resource-name anystring NX EX max-lock-time 实现 * * &lt;p&gt; 该方案在 Redis 官方 SET 命令页有详细介绍。 http://doc.redisfans.com/string/set.html * * &lt;p&gt; 在介绍该分布式锁设计之前，我们先来看一下在从 Redis 2.6.12 开始 SET 提供的新特性， 命令 SET key value [EX seconds] [PX * milliseconds] [NX|XX]，其中： * * &lt;p&gt; EX seconds — 以秒为单位设置 key 的过期时间； PX milliseconds — 以毫秒为单位设置 key 的过期时间； NX — 将key 的值设为value * ，当且仅当key 不存在，等效于 SETNX。 XX — 将key 的值设为value ，当且仅当key 存在，等效于 SETEX。 * * &lt;p&gt; 命令 SET resource-name anystring NX EX max-lock-time 是一种在 Redis 中实现锁的简单方法。 * * &lt;p&gt; 客户端执行以上的命令： * * &lt;p&gt; 如果服务器返回 OK ，那么这个客户端获得锁。 如果服务器返回 NIL ，那么客户端获取锁失败，可以在稍后再重试。 */@Slf4jpublic class SmartRedisLock &#123; private StringRedisTemplate redisTemplate; /** * 将key 的值设为value ，当且仅当key 不存在，等效于 SETNX。 */ private static final String NX = "NX"; /** * seconds — 以秒为单位设置 key 的过期时间，等效于EXPIRE key seconds */ private static final String EX = "EX"; /** * 调用set后的返回值 */ private static final String OK = "OK"; /** * 默认请求锁的超时时间(ms 毫秒) */ private static final long TIME_OUT = 1000; /** * 默认锁的有效时间(s) */ private static final int EXPIRE = 60; /** * 解锁的lua脚本 */ private static final String UNLOCK_LUA; /** * KEYS数组的内容 * -- KEYS[1] - key -- KEYS[2] - ttl in ms -- KEYS[3] - lock content */ static &#123; StringBuilder sb = new StringBuilder(); sb.append("if redis.call(\"get\",KEYS[1]) == ARGV[1] "); sb.append("then "); sb.append(" return redis.call(\"del\",KEYS[1]) "); sb.append("else "); sb.append(" return 0 "); sb.append("end "); UNLOCK_LUA = sb.toString(); &#125; /** * 锁标志对应的key */ private String lockKey; /** * 锁对应的值 */ private String lockValue; /** * 锁的有效时间(s) */ private long expireTime = EXPIRE; /** * 锁标记：保证一个线程修改了值，其他线程立即能获取到最新的值 */ private volatile boolean locked = false; private final Random random = new Random(); /** * 使用默认的锁过期时间和请求锁的超时时间 * * @param lockKey 锁的key（Redis的Key） */ public SmartRedisLock(StringRedisTemplate redisTemplate, String lockKey) &#123; this.redisTemplate = redisTemplate; this.lockKey = lockKey + "_lock"; &#125; /** * 使用默认的请求锁的超时时间，指定锁的过期时间 * * @param lockKey 锁的key（Redis的Key） * @param expireTime 锁的过期时间(单位：秒) */ public SmartRedisLock(StringRedisTemplate redisTemplate, String lockKey, long expireTime) &#123; this(redisTemplate, lockKey); this.expireTime = expireTime; &#125; /** * 尝试获取锁 超时返回,在超时时间内会重试 */ public boolean tryLock() &#123; // 生成随机key lockValue = UUID.randomUUID().toString(); // 请求锁超时时间， long nowTime = System.nanoTime(); while ((System.nanoTime() - nowTime) &lt; TIME_OUT * 1000000) &#123; if (OK.equalsIgnoreCase(this.set(lockKey, lockValue, expireTime))) &#123; locked = true; // 上锁成功结束请求 return true; &#125; // 每次请求等待一段时间 seleep(); &#125; return locked; &#125; /** * 使用场景：同一个时间点，只允许一个线程请求，其余线程拒绝 * * 尝试获取锁 立即返回 * * @return 是否成功获得锁 */ public boolean lock() &#123; lockValue = UUID.randomUUID().toString(); //不存在则添加 且设置过期时间（单位ms） String result = set(lockKey, lockValue, expireTime); locked = OK.equalsIgnoreCase(result); return locked; &#125; /** * 以阻塞方式的获取锁(等待前一个线程释放) * * 使用场景：多线程请求时，排队请求 * * @return 是否成功获得锁 */ public boolean lockBlock() &#123; lockValue = UUID.randomUUID().toString(); while (true) &#123; //不存在则添加 且设置过期时间（单位ms） String result = set(lockKey, lockValue, expireTime); if (OK.equalsIgnoreCase(result)) &#123; locked = true; return locked; &#125; // 每次请求等待一段时间 seleep(); &#125; &#125; /** * 解锁 &lt;p&gt; 可以通过以下修改，让这个锁实现更健壮： * * &lt;p&gt; 不使用固定的字符串作为键的值，而是设置一个不可猜测（non-guessable）的长随机字符串，作为口令串（token）。 * * 不使用 DEL 命令来释放锁，而是发送一个 Lua 脚本，这个脚本只在客户端传入的值和键的口令串相匹配时，才对键进行删除。 * * 这两个改动可以防止持有过期锁的客户端误删现有锁的情况出现。 */ public Boolean unlock() &#123; // 只有加锁成功并且锁还有效才去释放锁 if (locked) &#123; return redisTemplate.execute(new RedisCallback&lt;Boolean&gt;() &#123; @Override public Boolean doInRedis(RedisConnection connection) throws DataAccessException &#123; Object nativeConnection = connection.getNativeConnection(); Long result = 0L; List&lt;String&gt; keys = new ArrayList&lt;&gt;(); keys.add(lockKey); List&lt;String&gt; values = new ArrayList&lt;&gt;(); values.add(lockValue); // 集群模式 if (nativeConnection instanceof JedisCluster) &#123; result = (Long) ((JedisCluster) nativeConnection).eval(UNLOCK_LUA, keys, values); &#125; // 单机模式 if (nativeConnection instanceof Jedis) &#123; result = (Long) ((Jedis) nativeConnection).eval(UNLOCK_LUA, keys, values); &#125; if (result == 0) &#123; log.info("Redis分布式锁，解锁&#123;&#125;失败！解锁时间：&#123;&#125;", System.currentTimeMillis()); &#125; locked = result == 0; return result == 1; &#125; &#125;); &#125; return true; &#125; /** * 重写redisTemplate的set方法 * * 命令 SET resource-name anystring NX EX max-lock-time 是一种在 Redis 中实现锁的简单方法。 * * &lt;p&gt; 客户端执行以上的命令： * * &lt;p&gt; 如果服务器返回 OK ，那么这个客户端获得锁。 如果服务器返回 NIL ，那么客户端获取锁失败，可以在稍后再重试。 * * @param key 锁的Key * @param value 锁里面的值 * @param seconds 过去时间（秒） */ private String set(final String key, final String value, final long seconds) &#123; log.debug("lockKey:&#123;&#125;", key); Assert.isTrue(!StringUtils.isEmpty(key), "key不能为空"); return redisTemplate.execute(new RedisCallback&lt;String&gt;() &#123; @Override public String doInRedis(RedisConnection connection) throws DataAccessException &#123; Object nativeConnection = connection.getNativeConnection(); String result = null; if (nativeConnection instanceof JedisCommands) &#123; result = ((JedisCommands) nativeConnection).set(key, value, NX, EX, seconds); &#125; return result; &#125; &#125;); &#125; /** * @Title: seleep * @Description: 线程等待时间 */ private void seleep() &#123; try &#123; Thread.sleep(10, random.nextInt(50000)); &#125; catch (InterruptedException e) &#123; log.info("获取分布式锁休眠被中断：", e); &#125; &#125;&#125;]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis实现全局ID生成器]]></title>
    <url>%2F2018%2F05%2F09%2FRedis%E5%AE%9E%E7%8E%B0%E5%85%A8%E5%B1%80ID%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[在分布式系统架构中，经常都需要一个全局的ID生成器，来保证系统中某些业务场景中对于主键的要求，当前实现ID生成的方式还是挺多的，本文我们主要介绍下如何使用Redis的incr机制实现全局ID生成。 Redis的incr命令对存储在指定key的数值执行原子的加1操作。 如果指定的key不存在，那么在执行incr操作之前，会先将它的值设定为0。 如果指定的key中存储的值不是字符串类型或者存储的字符串类型不能表示为一个整数 那么执行这个命令时服务器会返回一个错误(eq:(error) ERR value is not an integer or out of range)。 实现思路 1、定义一个通用的key，该key的规则是时间格式，精确到秒，保证每秒都是不同的key，value的值是一个long型的整数，前半部分是当前时间精确到秒，后面是自增的值，设计成5位，不够的补0，这样基本就是每秒最多能生成99999个ID，基本能满足大部分的需求，如果需要更多，可以多保留几位就行。 123456789101112131415/** * 使用redis生成分布式ID */public interface IdGeneratorService &#123; /** * @param biz 业务名称 */ long generatorId(String biz); /** * * @return */ long generatorId(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package com.smart.server.idgen.redis;import com.google.common.base.Strings;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.ValueOperations;import org.springframework.stereotype.Service;import java.util.Calendar;import java.util.Date;import java.util.concurrent.TimeUnit;import lombok.extern.slf4j.Slf4j;@Service@Slf4jpublic class RedisIdGeneratorService implements IdGeneratorService &#123; private static final String keyPrefix = "smart"; /** * JedisClient对象 */ @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; /** * @Description * @author butterfly */ private String getIDPrefix() &#123; Date date = new Date(); Calendar c = Calendar.getInstance(); c.setTime(date); int year = c.get(Calendar.YEAR); int day = c.get(Calendar.DAY_OF_YEAR); // 今天是第多少天 int hour = c.get(Calendar.HOUR_OF_DAY); int minute = c.get(Calendar.MINUTE); int second = c.get(Calendar.SECOND); String dayFmt = String.format("%1$03d", day); // 0补位操作 必须满足三位 String hourFmt = String.format("%1$02d", hour); // 0补位操作 必须满足2位 String minuteFmt = String.format("%1$02d", minute); // 0补位操作 必须满足2位 String secondFmt = String.format("%1$02d", second); // 0补位操作 必须满足2位 StringBuffer prefix = new StringBuffer(); prefix.append((year - 2000)).append(dayFmt).append(hourFmt).append(minuteFmt).append(secondFmt); return prefix.toString(); &#125; /** * @author butterfly */ private long incrDistrId(String biz) &#123; String prefix = getIDPrefix(); String orderId = null; String key = "#&#123;biz&#125;:id:".replace("#&#123;biz&#125;", biz).concat(prefix); // 00001 try &#123; ValueOperations&lt;String, Object&gt; valueOper = redisTemplate.opsForValue(); Long index = valueOper.increment(key, 1); orderId = prefix.concat(String.format("%1$05d", index)); // 补位操作 保证满足5位 &#125; catch (Exception ex) &#123; log.error("分布式订单号生成失败异常。。。。。", ex); &#125; finally &#123; redisTemplate.expire(key, 600, TimeUnit.SECONDS);//保留10分钟内的key &#125; if (Strings.isNullOrEmpty(orderId)) return 0; return Long.parseLong(orderId); &#125; /** * @Description 生成分布式ID * @author butterfly */ @Override public long generatorId(String biz) &#123; // 转成数字类型，可排序 return incrDistrId(biz); &#125; @Override public long generatorId() &#123; return incrDistrId(keyPrefix); &#125;&#125; 单元测试12345678910111213141516171819202122232425262728293031323334353637383940package com.test;import com.smart.server.Application;import com.smart.server.idgen.redis.IdGeneratorService;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import lombok.extern.slf4j.Slf4j;/** * @author gaowenming * @create 2018-05-08 11:10 * @desc **/@RunWith(SpringRunner.class)@SpringBootTest(classes = Application.class)@Slf4jpublic class IDTest &#123; @Autowired private IdGeneratorService idGeneratorService; @Test public void testRedisId() throws InterruptedException &#123; for (int i = 0; i &lt; 1000; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; log.info(idGeneratorService.generatorId() + ""); &#125; &#125;).start(); &#125; Thread.sleep(10000); &#125;&#125; 总结 Redis实现ID生成的方式实现起来还是挺简单的，当然优缺点也是存在的优点：1、能够一定程度上保持Id具有一定的增长规律，有利于索引和排序2、比较灵活，可以根据自己的需要，定制不同的ID的格式缺点：1、依赖于Redis，需要引入Redis中间件的配置2、服务端统一生成，和本地生成的效率相比，还是差一点]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch(六) 使用Jest实现基本的索引操作和搜索]]></title>
    <url>%2F2018%2F02%2F06%2FElasticsearch-%E5%85%AD-%E4%BD%BF%E7%94%A8Jest%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%B4%A2%E5%BC%95%E6%93%8D%E4%BD%9C%E5%92%8C%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[本文主要是Jest Api的实例介绍，包括index的创建，mapping的设置，基本的条件搜索等。本文中的实现是基于SpringBoot，而且SpringBoot中已经内置了Jest的starter，所以配置起来还是很简单的。 配置ElasticsearchSpringBoot中已经内置了Elasticsearch的starter，我们只需要在Properties文件中配置Elasticsearch的连接信息即可12345#jestspring.elasticsearch.jest.uris=http://127.0.0.1:9200spring.elasticsearch.jest.read-timeout=10000spring.elasticsearch.jest.username=elasticspring.elasticsearch.jest.password=changme index通用接口 1、首先抽象出一个公共类，该类中的方法是对index的基本操作(索引创建、删除、优化、mapping创建、mapping追加)，与index中的数据无关，CommonJestIndexService 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226package com.smart.elasticsearch.core.base;import com.google.gson.JsonObject;import org.elasticsearch.common.xcontent.XContentBuilder;import org.elasticsearch.common.xcontent.XContentFactory;import org.springframework.stereotype.Service;import java.io.IOException;import javax.annotation.Resource;import io.searchbox.client.JestClient;import io.searchbox.client.JestResult;import io.searchbox.client.JestResultHandler;import io.searchbox.indices.ClearCache;import io.searchbox.indices.CreateIndex;import io.searchbox.indices.DeleteIndex;import io.searchbox.indices.IndicesExists;import io.searchbox.indices.Optimize;import io.searchbox.indices.mapping.GetMapping;import io.searchbox.indices.mapping.PutMapping;import lombok.extern.slf4j.Slf4j;/** * 索引操作 * * @author gaowenming * @create 2018-02-01 17:45 * @desc **/@Service@Slf4jpublic class CommonJestIndexService &#123; @Resource private JestClient jestClient; /** * 创建index */ public void createIndex(String index) &#123; try &#123; JestResult jestResult = jestClient.execute(new CreateIndex.Builder(index).build()); log.info("createIndex:&#123;&#125;", jestResult.isSucceeded()); &#125; catch (IOException e) &#123; log.error("createIndex error:", e); &#125; &#125; /** * （设置数据类型和分词方式） * * 设置index的mapping */ public void createIndexMapping(String index, String type, String mappingString) &#123; PutMapping.Builder builder = new PutMapping.Builder(index, type, mappingString); try &#123; JestResult jestResult = jestClient.execute(builder.build()); log.info("createIndexMapping result:&#123;&#125;", jestResult.isSucceeded()); if (!jestResult.isSucceeded()) &#123; log.error("settingIndexMapping error:&#123;&#125;", jestResult.getErrorMessage()); &#125; &#125; catch (IOException e) &#123; log.error("settingIndexMapping error:", e); &#125; &#125; /** * 追加mapping字段 * * @param index index名称 * @param type type名称 * @param fieldName 字段名称 * @param fieldType 字段类型 * @param analyze 是否分词 */ public void addFieldMapping(String index, String type, String fieldName, String fieldType, boolean analyze) &#123; String mapping; XContentBuilder mapBuilder = null; try &#123; mapBuilder = XContentFactory.jsonBuilder(); //设置分词 if (analyze) &#123; mapBuilder.startObject() .startObject(type) .startObject("properties") .startObject(fieldName).field("type", fieldType).field("analyzer", "ik_max_word").field("store", "yes").endObject() .endObject() .endObject() .endObject(); &#125; else &#123; mapBuilder.startObject() .startObject(type) .startObject("properties") .startObject(fieldName).field("type", fieldType).field("index", "not_analyzed").field("store", "yes").endObject() .endObject() .endObject() .endObject(); &#125; mapping = mapBuilder.string(); PutMapping.Builder builder = new PutMapping.Builder(index, type, mapping); JestResult jestResult = jestClient.execute(builder.build()); log.info("addFieldMapping result:&#123;&#125;", jestResult.isSucceeded()); if (!jestResult.isSucceeded()) &#123; log.error("addFieldMapping error:&#123;&#125;", jestResult.getErrorMessage()); &#125; &#125; catch (IOException e) &#123; log.error("addFieldMapping error", e); &#125; &#125; /** * 追加mapping字段 * * @param index index名称 * @param type type名称 * @param fieldName 字段名称 * @param format 日期格式 */ public void addDateFieldMapping(String index, String type, String fieldName, String format) &#123; String mapping; XContentBuilder mapBuilder = null; try &#123; mapBuilder = XContentFactory.jsonBuilder(); mapBuilder.startObject() .startObject(type) .startObject("properties") .startObject(fieldName).field("type", "date").field("format", format).field("store", "yes").endObject() .endObject() .endObject() .endObject(); mapping = mapBuilder.string(); PutMapping.Builder builder = new PutMapping.Builder(index, type, mapping); JestResult jestResult = jestClient.execute(builder.build()); log.info("addDateFieldMapping result:&#123;&#125;", jestResult.isSucceeded()); if (!jestResult.isSucceeded()) &#123; log.error("addDateFieldMapping error:&#123;&#125;", jestResult.getErrorMessage()); &#125; &#125; catch (IOException e) &#123; log.error("addDateFieldMapping error", e); &#125; &#125; /** * 获取index的mapping */ public String getMapping(String indexName, String typeName) &#123; GetMapping.Builder builder = new GetMapping.Builder(); builder.addIndex(indexName).addType(typeName); try &#123; JestResult result = jestClient.execute(builder.build()); if (result != null &amp;&amp; result.isSucceeded()) &#123; return result.getSourceAsObject(JsonObject.class).toString(); &#125; &#125; catch (Exception e) &#123; log.error("getMapping error", e); &#125; return null; &#125; /** * 判断index是否存在 */ public boolean indexExist(String index) &#123; IndicesExists indicesExists = new IndicesExists.Builder(index).build(); try &#123; JestResult jestResult = jestClient.execute(indicesExists); if (jestResult != null) &#123; return jestResult.isSucceeded(); &#125; &#125; catch (IOException e) &#123; log.error("indexExist error", e); &#125; return false; &#125; /** * 删除index */ public void deleteIndex(String index) &#123; try &#123; JestResult jestResult = jestClient.execute(new DeleteIndex.Builder(index).build()); log.info("deleteIndex result:&#123;&#125;", jestResult.isSucceeded()); &#125; catch (IOException e) &#123; log.error("deleteIndex error", e); &#125; &#125; /** * 索引优化 */ public void optimizeIndex() &#123; Optimize optimize = new Optimize.Builder().build(); jestClient.executeAsync(optimize, new JestResultHandler&lt;JestResult&gt;() &#123; @Override public void completed(JestResult jestResult) &#123; log.info("optimizeIndex result:&#123;&#125;", jestResult.isSucceeded()); &#125; @Override public void failed(Exception e) &#123; log.error("optimizeIndex error", e); &#125; &#125;); &#125; /** * 清理缓存 */ public void clearCache() &#123; try &#123; ClearCache clearCache = new ClearCache.Builder().build(); jestClient.execute(clearCache); &#125; catch (IOException e) &#123; log.error("clearCache error", e); &#125; &#125;&#125; 数据操作接口 定义泛型接口，进行index中数据的操作，比如添加索引数据，删除索引数据，简单查询 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.smart.elasticsearch.core.base;import com.smart.elasticsearch.core.result.SmartSearchResult;import java.util.List;/** * 索引中数据的操作（增删改查） * * @author gaowenming * @create 2018-01-31 11:43 * @desc jestSearch **/public interface JestDataBaseService&lt;T&gt; &#123; /** * 单条删除 */ boolean deleteItem(String index, String type, String id); /** * 批量创建索引 */ void batchIndex(String index, String type, List&lt;T&gt; list); /** * 单条索引(新增/更新) */ void singleIndex(String index, String type, T t); /** * 指定索引ID */ void singleIndexWithId(String index, String type, String id, T t); /** * 根据id查询 */ T queryById(String index, String type, String id, Class&lt;T&gt; clazz); /** * 无过滤条件 */ SmartSearchResult&lt;T&gt; queryAll(String index, String type, int fetchSize, Class&lt;T&gt; clazz); /** * 设置type的mapping */ String buildIndexMapping(String type);&#125; 抽象实现 泛型接口定义完，我们需要实现其中的方法了，这里我们采用抽象类的实现方式，这样实现的目的是为了我们在定义其他接口时，直接extend该抽象类，即可复用其中的实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package com.smart.elasticsearch.core.base;import com.smart.elasticsearch.core.result.SmartSearchResult;import com.smart.elasticsearch.core.result.SmartSearchResultConverter;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.builder.SearchSourceBuilder;import org.elasticsearch.search.sort.SortOrder;import java.io.IOException;import java.util.List;import javax.annotation.Resource;import io.searchbox.client.JestClient;import io.searchbox.client.JestResult;import io.searchbox.core.Bulk;import io.searchbox.core.Delete;import io.searchbox.core.Get;import io.searchbox.core.Index;import io.searchbox.core.Search;import io.searchbox.core.SearchResult;import lombok.extern.slf4j.Slf4j;/** * elasticsearch通用操作 * * @author gaowenming * @create 2018-02-01 14:21 * @desc **/@Slf4jpublic abstract class AbstractJestDataBaseService&lt;T&gt; implements JestDataBaseService&lt;T&gt; &#123; @Resource private JestClient jestClient; @Override public boolean deleteItem(String index, String type, String id) &#123; try &#123; JestResult jestResult = jestClient.execute(new Delete.Builder(id).index(index).type(type).refresh(true).build()); if (!jestResult.isSucceeded()) &#123; log.error("deleteItem error:&#123;&#125;", jestResult.getErrorMessage()); &#125; return jestResult.isSucceeded(); &#125; catch (IOException e) &#123; log.error("deleteItem error", e); &#125; return false; &#125; @Override public void batchIndex(String index, String type, List&lt;T&gt; list) &#123; try &#123; Bulk.Builder builder = new Bulk.Builder(); for (T t : list) &#123; builder.addAction(new Index.Builder(t).index(index).type(type).build()); &#125; JestResult jestResult = jestClient.execute(builder.build()); if (!jestResult.isSucceeded()) &#123; log.error("batchIndex error:&#123;&#125;", jestResult.getErrorMessage()); &#125; &#125; catch (IOException e) &#123; log.error("batchIndex error", e); &#125; &#125; @Override public void singleIndex(String index, String type, T t) &#123; try &#123; JestResult jestResult = jestClient.execute(new Index.Builder(t).index(index).type(type).build()); if (!jestResult.isSucceeded()) &#123; log.error("singleIndex error:&#123;&#125;", jestResult.getErrorMessage()); &#125; &#125; catch (IOException e) &#123; log.error("singleIndex error", e); &#125; &#125; @Override public T queryById(String index, String type, String id, Class&lt;T&gt; clazz) &#123; T result = null; try &#123; Get get = new Get.Builder(index, id).type(type).build(); JestResult jestResult = jestClient.execute(get); result = jestResult.getSourceAsObject(clazz); &#125; catch (IOException e) &#123; log.error("queryById error", e); &#125; return result; &#125; @Override public void singleIndexWithId(String index, String type, String id, T t) &#123; try &#123; JestResult jestResult = jestClient.execute(new Index.Builder(t).index(index).type(type).id(id).build()); if (!jestResult.isSucceeded()) &#123; log.error("singleIndexWithId error:&#123;&#125;", jestResult.getErrorMessage()); &#125; &#125; catch (IOException e) &#123; log.error("singleIndexWithId error", e); &#125; &#125; @Override public SmartSearchResult&lt;T&gt; queryAll(String index, String type, int fetchSize, Class&lt;T&gt; clazz) &#123; SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery()).size(fetchSize).sort("id", SortOrder.DESC); Search search = new Search.Builder(searchSourceBuilder.toString()) .addIndex(index).addType(type) .build(); log.info("search query:&#123;&#125;", searchSourceBuilder); SearchResult result; SmartSearchResult&lt;T&gt; smartSearchResult = null; try &#123; result = jestClient.execute(search); smartSearchResult = SmartSearchResultConverter.searchResultFormatter(result, clazz); &#125; catch (IOException e) &#123; log.error("queryAll error", e); &#125; return smartSearchResult; &#125;&#125; Blog实例 上面几个类，都是从底层实现的角度来封装Elasticsearch的操作，下面我们用一个实际的例子来应用，加入我们把博客内容存放在Elasticsearch中。 12345678910111213141516171819package com.smart.elasticsearch.blog.service;import com.smart.elasticsearch.blog.domain.Blog;import com.smart.elasticsearch.blog.param.SearchParam;import com.smart.elasticsearch.core.base.JestDataBaseService;import com.smart.elasticsearch.core.result.SmartSearchResult;/** * @author gaowenming * @create 2018-01-31 11:43 * @desc jestSearch **/public interface BlogJestService extends JestDataBaseService&lt;Blog&gt; &#123; /** * 通用查询 */ SmartSearchResult&lt;Blog&gt; queryBySearchParam(SearchParam searchParam);&#125; 定义了BlogJestService，继承了泛型接口，再新加了一个通用的搜索接口，基本上对Blog的索引操作都包含了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.smart.elasticsearch.blog.service;import com.smart.elasticsearch.blog.domain.Blog;import com.smart.elasticsearch.blog.param.SearchParam;import com.smart.elasticsearch.blog.query.BlogSearchRequest;import com.smart.elasticsearch.core.base.AbstractJestDataBaseService;import com.smart.elasticsearch.core.result.SmartSearchResult;import org.elasticsearch.common.xcontent.XContentBuilder;import org.elasticsearch.common.xcontent.XContentFactory;import org.springframework.stereotype.Service;import java.io.IOException;import javax.annotation.Resource;import lombok.extern.slf4j.Slf4j;/** * @author gaowenming * @create 2018-02-01 15:13 * @desc **/@Slf4j@Service("blogJestService")public class BlogJestServiceImpl extends AbstractJestDataBaseService&lt;Blog&gt; implements BlogJestService &#123; @Resource private BlogSearchRequest blogSearchRequest; @Override public String buildIndexMapping(String type) &#123; String mapping = ""; XContentBuilder mapBuilder = null; try &#123; mapBuilder = XContentFactory.jsonBuilder(); mapBuilder.startObject() .startObject(type) .startObject("properties") .startObject("id").field("type", "long").field("store", "yes").endObject() //设置分词 .startObject("title").field("type", "string").field("analyzer", "ik_max_word").field("store", "no").endObject() .startObject("content").field("type", "string").field("analyzer", "ik_max_word").field("store", "yes").endObject() //不分词 .startObject("author").field("type", "string").field("index", "not_analyzed").field("store", "no").endObject() .startObject("tags").field("type", "string").field("index", "not_analyzed").field("store", "no").endObject() .startObject("categroy").field("type", "string").field("index", "not_analyzed").field("store", "no").endObject() .startObject("createTime").field("type", "long").field("index", "not_analyzed").field("store", "no").endObject() .startObject("lastUpdateTime").field("type", "date").field("format", "yyyy-MM-dd HH:mm:ss").field("store", "no").endObject() .endObject() .endObject() .endObject(); mapping = mapBuilder.string(); &#125; catch (IOException e) &#123; log.error("buildIndexMapping error", e); &#125; return mapping; &#125; @Override public SmartSearchResult&lt;Blog&gt; queryBySearchParam(SearchParam searchParam) &#123; return blogSearchRequest.buildSearchRequest(searchParam); &#125;&#125; Blog的实现类也很简单，继承AbstractJestDataBaseService抽象类，只需要实现未实现的接口即可。上面的实现中，我们对设置Mapping的方法进行了实现，对每个字段的mapping都进行设置。 总结 Elasticsearch的Jest Api进行简单的封装，把基本的，通用的操作封装到一起实现，比如我们Elasticsearch中存放Blog和User，都有index的创建，删除等基本操作，抽象出来，对代码的整洁性，可维护性也是很有好处的，我们在Elasticsearch中增加一个新的index，只需要关注mapping和search方面的接口，其他的操作都抽象成通用的方法，也很大的节省了重复的工作。完整的代码地址：https://github.com/gaowenming/spring-boot-elasticsearch]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch(五) java客户端介绍]]></title>
    <url>%2F2018%2F02%2F06%2FElasticsearch-%E4%BA%94-java%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[操作Elasticsearch的api众多，java语言领域主要有3种，和官方server一起发布的Transport client，searchbox-io提供的Jest，还有Spring-Data提供的Spring Data ElasticSearch Transport客户端 java transport api提供了Query Builder来协助构建查询对象，而http则需要自己在代码里拼JSON DSL，从程序员角度来说， java transport api更显得更加友好，并且性能也要比http稍好。 但java transport api也有如下弊病: 第三方依赖包比较多，如果应用还要集成其他一些框架和组件，容易产生依赖冲突，解决起来比较麻烦。 client版本必须和ES服务端版本一致，否则容易产生兼容性问题。 client端JAVA版本也需要和Server端保持一致，否则也可能产生兼容性问题。 client端的环境和版本需要和server端保持一致这个要求，使得client/server端运行环境强耦合，导致ES Server端很难独立升级。 官方的roadmap也指明，未来java transport api会被取消，建议使用rest client。 Spring Data ElasticSearch Spring Data ElasticSearch 也是提供了一层封装，使得操作Elasticsearch变得更简单，但是扩展性不强，而且最近更新的比较慢，使得后面的最新版本都无法支持 Searchbox-io jestjest是Searchbox提供的基于Http协议的客户端 jest是一款java Rest client，它支持SSL、proxy等等，而原生的transport client是TCP连接，用户认证授权要自己想办法实现，并且封装接口控制用户的操作。 原生的API没有任何安全保护层，而对于HTTP来说加一层安全认证是比较简单的。 jest client和原生的client的比较还有： 如果ES集群的版本不同，用HTTP client会好些。如果版本不是问题，原生的client可能更好。因为它是culster-aware的，并且可以从ES集群分担一部分计算，比如合并搜索结果是在本地client执行的而不是data node。 原生的client像一个单纯的节点连接集群，它知道集群的状态和路由请求，这样会消耗多一些内存，在生产环境是值得考虑的影响。 如果使用SpringBoot的话，已经内置了starter，很快速的就能接入12345#jestspring.elasticsearch.jest.uris=http://localhost:9200spring.elasticsearch.jest.read-timeout=10000spring.elasticsearch.jest.username=elasticspring.elasticsearch.jest.password=changme 总结 1、首先对于Elasticsearch的版本敏感度来说，jest几乎是不怎么受影响的，但是Transport和SpringData要求版本一致性更高2、client的更新速度上，transport和jest都还不错，能最快速度支持新版本，SpringData最差，现在已经跟不上版本的发布速度了3、Transport计划从发布中废除，而且安全上，也是不利于维护 从以上几点比较上，当前阶段，最推荐的方式还是使用jest来操作Elasticsearch。]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch(四) IK分词器]]></title>
    <url>%2F2018%2F02%2F06%2FElasticsearch-%E5%9B%9B-IK%E5%88%86%E8%AF%8D%E5%99%A8%2F</url>
    <content type="text"><![CDATA[分词是Elasticsearch中非常重要的组件，毕竟官方的分词器很傻瓜，无法满足实际的业务需求。 IK分词器 这里主要介绍下IK分词器的安装和使用方法 1. 安装IK插件 安装IK分词插件非常简单， github地址：https://github.com/medcl/elasticsearch-analysis-ik/需要注意的是，ELasticsearch是版本非常敏感的，所以在安装IK插件的时候，一定要注意和自己的版本对应。我使用的版本是5.6.01./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v5.6.0/elasticsearch-analysis-ik-5.6.0.zip 安装完出现1Installed analysis-ik 表示安装成功。测试一下： mapping中指定IK分词方式如果某个字段需要进行分词，那么在设计mapping时，就需要指定。1234567891011.startObject("properties") .startObject("id").field("type", "long").field("store", "yes").endObject() //设置分词 .startObject("title").field("type", "string").field("analyzer", "ik_max_word").field("store", "no").endObject() .startObject("content").field("type", "string").field("analyzer", "ik_max_word").field("store", "yes").endObject() //不分词 .startObject("author").field("type", "string").field("index", "not_analyzed").field("store", "no").endObject() .startObject("tags").field("type", "string").field("index", "not_analyzed").field("store", "no").endObject() .startObject("categroy").field("type", "string").field("index", "not_analyzed").field("store", "no").endObject() .startObject("createTime").field("type", "long").field("index", "not_analyzed").field("store", "no").endObject() .startObject("lastUpdateTime").field("type", "date").field("format", "yyyy-MM-dd HH:mm:ss").field("store", "no").endObject() 很简单，只需要上面2步，就完成了分词器的设置。]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch(三) mapping设置]]></title>
    <url>%2F2018%2F02%2F06%2FElasticsearch-%E4%B8%89-mapping%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[之前介绍了Elasticsearch中的数据类型，那如何来定义数据类型呢？这就需要用到Mapping了。 Mapping是什么 通俗的解释，mapping和关系型数据库中的schema类似，就是对字段数据存储的描述，包括字段的类型，是否需要分词，怎么分词等。先看一个index中type的mapping说明123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; "smart":&#123; "mappings":&#123; "blog":&#123; "properties":&#123; "author":&#123; "type":"keyword", "store":true &#125;, "categroy":&#123; "type":"keyword", "store":true &#125;, "content":&#123; "type":"text", "store":true, "analyzer":"ik_max_word" &#125;, "createTime":&#123; "type":"long", "store":true &#125;, "id":&#123; "type":"long", "store":true &#125;, "lastUpdateTime":&#123; "type":"date", "store":true, "format":"yyyy-MM-dd HH:mm:ss" &#125;, "tags":&#123; "type":"keyword", "store":true &#125;, "title":&#123; "type":"text", "store":true, "analyzer":"ik_max_word" &#125; &#125; &#125; &#125; &#125;&#125; 主要的属性如下： 1. type type是指该属性的类型，之前也介绍过了，可以根据属性的值设置合适的类型 2. index index是设置该属性是否需要分词，默认的分词是把中文拆成每个汉字，不友好，我们可以设置自己的分词方式，比如ik_smart,ik_max_word 3. boost boost表示该属性的权重，值越大，权重越高 4. store store 的意思是，是否在 _source 之外在独立存储一份，这里要说一下 _source 这是源文档，当你索引数据的时候， elasticsearch 会保存一份源文档到 _source ，如果文档的某一字段设置了 store 为 yes (默认为 no)，这时候会在 _source 存储之外再为这个字段独立进行存储，这么做的目的主要是针对内容比较多的字段，放到 _source 返回的话，因为_source 是把所有字段保存为一份文档，命中后读取只需要一次 IO，包含内容特别多的字段会很占带宽影响性能，通常我们也不需要完整的内容返回(可能只关心摘要)，这时候就没必要放到 _source 里一起返回了(当然也可以在查询时指定返回字段)。 对内容太长的字段，将 store 设置为 yes ，一般来说还应该在 _source 排除 exclude 掉这个字段，这时候索引的字段，不会保存在 _source 里了，会独立存储一份，查询时 _source 里也没有这个字段了，但是还是可以通过指定返回字段来获取，但是会有额外的 IO 开销，因为 _source 的读取只有一次 IO ，而已经 exclude 并设置 store 的字段，是独立存储的需要一个新的 IO 。]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch(二) ES中的数据结构]]></title>
    <url>%2F2018%2F02%2F06%2FElasticsearch-%E4%BA%8C-ES%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[在关系型数据库中，表中的字段都是需要定义类型的，在Elasticsearch中，同样也有类型的概念。 核心类型 字符类型字符类型包括：text，keyword text类型：分词，将大段的文字根据分词器切分成独立的词或者词组，以便全文检索。适用：email内容、描述等需要分词全文检索的字段；不适用：排序或聚合（Significant Terms 聚合例外）keyword类型：无需分词、整段完整精确匹配。适用：email地址、住址、状态码、分类tags。 数值类型 longintegershortbytedoublefloathalf_float半精度浮点型：半精度16位IEEE 754浮点数。scaled_float：由长度固定的缩放因子支持的浮点数。以上，根据长度和精度选型即可。 日期类型 （date） “date”: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot; }日期类型需要指定日期的格式，而且es对日期的格式是很敏感的，所以需要严格的按照格式赋值 布尔值（boolean）字段的值为true、false 二进制 二进制类型接受二进制值作为Base64编码字符串。 该字段默认情况下不存储，不可搜索。如： “blob”: “U29tZSBiaW5hcnkgYmxvYg==” 复杂类型 数组类型 在Elasticsearch中，没有专门的数组类型。任何类型都可以组成数组类型，但是在数组中的数据，他们的类型必须是一致的， 对象类型 JSON文档本质上是分层的：存储类似json具有层级的数据，文档可能包含内部对象，而内部对象又可能包含其他内部对象。 嵌套类型 嵌套类型和对象类型有点类似，nested嵌套类型是Object数据类型的特定版本，允许对象数组彼此独立地进行索引和查询。 地理坐标 GEO Point _ geopoint 用于经纬度坐标。 GEO shape _ geoshape 用于类似于多边形的复杂形状，划定的地理围栏。 特定类型 IP IPv4 类型（IPv4 datatype）： ip 用于IPv4 地址；“ip_addr”: “192.168.1.1” Completion 类型 completion 提供自动补全建议； Token count _ tokencount 用于统计做了标记的字段的index数目，该值会一直增加，不会因为过滤条件而减少。 mapper-murmur3 通过插件，可以通过 murmur3 来计算 index 的 hash 值； Attachment datatype 附加类型（Attachment datatype）：采用 mapper-attachments插件，可支持 attachments 索引，例如 Microsoft Office 格式，Open Document 格式，ePub, HTML 等。]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch(一) ES中的基本概念]]></title>
    <url>%2F2018%2F02%2F06%2FElasticsearch-%E4%B8%80-ES%E4%B8%AD%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[Elasticsearch 使用一种称为倒排索引的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。 倒排索引索引我们都很熟悉，字典的索引，书籍的索引，比如关系型数据库中，我们经常需要设置索引来提高数据检索的效率，如下： id name 1 张三 2 李四 3 李二 比如我们在id列创建索引，就能快速的根据id的值检索到具体的行，每一条新的数据，id都是需要增加到索引文件中的。 什么是倒排索引？ 所谓倒排索引，就是每条记录中的content会被分割成最小的数据单元，每个数据单元都会指向该条记录，和正常的索引关系正好是相反的，如下图： keyword id java 1 redis 3 mq 1,2 spring 3,4 python 4 倒排的特点 在倒排索引中，关键字的数量并非随着文本内容的增长也线性增长。这因为不论多大数量的文本数据库，总能规范出一个关键词表搜到实际语言因素的限制，它的增长率在文本数据库达到一定规模后可以忽略不计。有人做过统计，对于1GB的文本信息来说，词汇表的大小在5MB左右。可以试想，将一本书上所有文本均制作成关键字，并对其进行倒排，构建一个信息搜索系统。对其中的内容进行检索，在整个过程中，最消耗时间的应该倒排阶段。因为在倒排时，需要对文本进行分析，切词，还要构建索引结构，记录位置信息，同时维护内容。虽然这一阶段花时间，但是一旦完成，在搜索时将会大大节省时间。事实上，一个信息检索系统在建立索引时的速度是可以放宽的，因为这是在后台异步完成的，而其搜索速度才是影响用户最终体验的直接因素。 词频和位置 通常，仅仅知道关键字的位置是远远不够再现实场景中完成搜索的，我们还需要知道关键词出现的次数和位置 keyword id 出现次数 位置 java 1 2 3,7 redis 3 1 2 mq 1,2 4 1,2,3,4 spring 3,4 5 2,4,6,5,7 python 4 3 1,2,3 实现时，Lucene将上面内容分别作为词典文件（TermDictionary）、频率文件（frequencies）、位置文件（positions）保存。其中词典文件不仅保存了每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。Lucene中使用了field的概念，用于表达信息所在位置（如标题中、文章中、URL中），在建索引中，该field信息也记录在词典文件中，每个关键词都有一个field信息，因为每个关键字一定属于一个或多个field。 索引和文档 在Elasticsearch中，文档归属于一种类型(type),而这些类型存在于索引(index)中，我们可以画一些简单的对比图来类比传统关系型数据库（只是来理解，其实不是很准确）：Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; ColumnsElasticsearch -&gt; Indices -&gt; Types -&gt; Documents -&gt; Fields Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）。 「索引」含义的区分 - Index index是具有相似特征的文档（document）集合。例如，你可以有顾客数据的index、商品种类的index和订单数据的index。每个index都有唯一的名称（必须小写），当执行索引、搜索、更新和删除操作时都需要根据该名称找到对应的index。 - Type type是index中的逻辑分类，在es中，在早期的版本中大家经常使用多个type，其实我们现在也还在用（用来批量移除历史数据），后来到5.X和现在的6.x中，都推荐用户一个index下面就用一个type，在后续的7.x规划中，已经计划把type从index中移除了，具体的原因，就是多个type存在很多坑。 人们经常会谈到index类似传统sql数据库的“database”,而type类似于”table”。现在想想，这是一个非常糟糕的比喻，而这个比喻会造成很多错误的假设。在传统的sql数据库中，各个”table”之间是互相独立的，在一个表中的列都与另一个表相同名称的列无关。 1，而在我们elasticsearch中同一 Index 下，同名 Field 类型必须相同，即使不同的 Type； 2， 同一 Index 下，TypeA 的 Field 会占用 TypeB 的资源（互相消耗资源），会形成一种稀疏存储的情况。尤其是 doc value ，为什么这么说呢？doc value为了性能考虑会保留一部分的磁盘空间，这意味着 TypeB 可能不需要这个字段的 doc_value 而 TypeA 需要，那么 TypeB 就被白白占用了一部分没有半点用处的资源； 3，Score 评分机制是 index-wide 的，不同的type之间评分也会造成干扰。 4，索引元数据本身是放在主节点中维护的，同一个index中多个type，会涉及到大量字段变更及元数据变更的操作，都会导致该 Index 被堵塞或假死。我们应该对这样的 Index 做隔离，避免影响到其他 Index 正常的增删改查！ - Document document是索引的基本单元信息。举例，你有一个客户的document、一个商品的document和一个订单的document。该document用JSON表示。 一个index/type中，可以包含任意多的document。注意，虽然document物理上存在index中，document实际上必须被分配到index中的type上。 - Field field就是document中的每个属性了，比如客户有id，(name)姓名，(sex)性别等 最后用一张图来说明下这几个概念]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ的消费延迟问题]]></title>
    <url>%2F2018%2F01%2F27%2FRabbitMQ%E7%9A%84%E6%B6%88%E8%B4%B9%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近一周系统出现几次消费MQ延迟的问题，最后定位到可能和MQ的延迟队列堆积数据太多有关。 异常现象最近一周，线上服务出现了几次消费RabbitMQ的延迟，具体的现象就是消费端（Consumer）有20秒的时间内，没有消费任何队列中的数据，好像和MQ断开连接一样，20秒后，所有队列又能正常消费了，有几个队列因为数据有先后的顺序逻辑，造成了部分数据的异常。 问题定位之前从来没有出现过这种问题，分析最近的上线内容，怀疑和上周一个同事上线的一个24小时的延迟队列有关，为什么这么说呢？这个24小时的延迟队列，大概里面是300多万的数据，占用内存是8G左右，之前就出现过消息生产端(Provider)往RabbitMQ扔消息延迟的情况。 看了下RabbitMQ的相关文档，发现好像是RabbitMQ内部有个限流机制，当数据超过了服务设置的警戒值，就会触发RabbitMQ的限流机制，比如降低消息的生产速度，这样在保证消费速度的前提下，MQ中的数据量会越来越少，但是为什么会引起Consumer无法消费的问题呢？看了下MQ的监控，发现在出现问题的时间点，MQ的波动很大，应该是出现了服务的短时间阻塞 从上面的监控图可以看出，MQ中的数据堆积到一定的数量后，会引起MQ服务的不稳定，从服务的波动上就可以看出，26日后面的曲线相对来说是比较平滑的，没有出现很剧烈的波动，因为25日就把该延迟队列迁移到另一个服务中。 问题总结 对于MQ的使用，在系统解耦方面是很常见的，延迟队列又能很好的解决我们系统上一些业务场景，比如延迟关闭过期订单。但是使用上我们还是需要注意几个问题： 是否使用ACK机制ACK，就是消息消费的确认机制，在消费队列中的消息时，我们可以指定是否采用ack，如果采用ack，则队列的消息需要在消费逻辑完成后通知队列，remove该条消息，如果不采用ack，默认就是consumer消费消息后，该消息自动从队列中remove。可以根据队列自身相关业务，决定是否需要采用ack机制，对于那些比较重要的消息，我觉得还是采用ack的机制比较好。 延迟队列的数据堆积延迟队列，意味着数据延迟消费，当然如果延迟时间比较长，那么堆积的数据也会越来越多，如果队列比较多的话，推荐大家把占用内存比较大，数据量比较多的延迟队列单独出来，这样即使出现性能问题，也不会影响到别的队列的正常运行。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊我们的灰度发布方案]]></title>
    <url>%2F2018%2F01%2F24%2F%E8%81%8A%E8%81%8A%E6%88%91%E4%BB%AC%E7%9A%84%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[在项目快速迭代的过程中，系统上线是我们日常非常频繁的工作，稳定可靠的部署方案就非常重要了。 部署方案当前主流的部署方案主要有如下几种： 蓝绿部署 蓝绿部署是不停老版本，部署新版本然后进行测试，确认OK，将流量切到新版本，然后老版本同时也升级到新版本。 滚动部署 滚动发布：一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本。 灰度部署 灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。ABtest就是一种灰度发布方式，让一部分用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 如何选择适合自己的方案上面几种方案，各有利弊，简单分析下蓝绿部署，占用资源比较多，因为需要2套完整的部署环境，但是有点也明显，2套环境完全隔离，验证完直接切换就行滚动部署，直接更新线上的节点验证，风险比较大，而且验证也不方便灰度部署，这种方式应该算是比较好的，我们可以把某个节点专门设为灰度节点，所有的上线前的验证都打到灰度节点，验证完之后，就可以全量更新。 我们的灰度方案经过一段时间的探索，我们也慢慢的完善了我们自己的灰度发布方案，总体的设计思路如下1、数据存储，灰度节点和线上节点共用一套，包括数据库MySql，Redis、Elasticsearch2、中间件单独一套，中间件包括ZK，MQ 为什么要这么做呢？ 分析起来也很容易理解，我们要想在灰度环境验证功能，首先要保证数据和线上是一致的，这样才能保证验证的场景一致，我们的数据主要包含数据库，缓存，索引数据。 中间件也很好理解，我们的服务现在主要是2种，提供API接口的Http服务，提供内部调用的Dubbo服务，流量从Nginx到达API服务后，怎么才能调度到我们的灰度节点呢？那就是通过ZK，Dubbo服务注册到ZK中，ZK和线上的服务区分开，这样就完成了灰度节点中的服务调用问题 MQ区分的原因是因为MQ是监听机制，只要监听了同一个服务，都可以消费到该服务的消息，所以把MQ单独出来，也就解决了线上数据被灰度节点消费的问题。 我们的总体灰度部署方案如下：]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>灰度发布</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot中Properties文件的解析]]></title>
    <url>%2F2018%2F01%2F21%2FSpring-Boot%E4%B8%ADProperties%E6%96%87%E4%BB%B6%E7%9A%84%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[项目中经常会把一些公共的配置放在Properties文件中，然后通过一些方法读取Properties文件的属性名和对应的值，通常都是解析成Map格式，在Spring Boot中，还提供了另一种更灵活的方式：自定义类，和Properties文件一一对应。 新建Properties文件新建一个文件，存放一些公共的配置12345678#1、组件集成之外的自定义配置，最好和部署环境无关的，和环境相关的，还是配置在application文件中#2、所有的key都加上smart前缀,防止和application中的key冲突#3、当前key/value的解析在SmartConfigProperties文件中，新增的key需要再类中声明即可smart.username=gaowenmingsmart.secretKey=123456789smart.id=1000smart.names=zhangsan,lisismart.weight=60.5 在上面的文件中，我们都加上smart前缀，这样更好的避免和别的配置重名 定义配置的公共类1234567891011121314151617181920import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import lombok.Data;/** * 业务配置 Author: gaowenming Description: Date: Created in 11:59 2017/7/15. */@Configuration@PropertySource("classpath:config.properties")//注意路径@ConfigurationProperties(prefix = "smart")@Datapublic class SmartConfigProperties &#123; private String username; private String secretKey; private int id; private String[] names; private float weight;&#125; Spring Boot中，可以支持Properties文件到类的类型转换，常规的类型和数组，List都支持，这样避免了我们自己解析后再强制类型转换，实现方式更优雅。 使用配置这种方式很好的把所有的配置都集中到一起，如果配置太多，我们也可以分多个类，避免一个类中太臃肿。使用起来也是很方便，直接把配置类注入到使用的地方即可12345678910111213141516171819202122@RestController@RequestMapping("api/test/")@Api@Slf4jpublic class TestController extends BaseController &#123; @Resource private SmartConfigProperties smartConfigProperties; @RequestMapping(value = "getConfigValue", method = RequestMethod.GET) public BaseJsonResult getConfigValue() throws Exception &#123; String[] names = smartConfigProperties.getNames(); for (String str : names) &#123; log.info(str); &#125; int id = smartConfigProperties.getId(); String username = smartConfigProperties.getUsername(); float weight = smartConfigProperties.getWeight(); log.info("names:&#123;&#125;,id:&#123;&#125;,username:&#123;&#125;,weight:&#123;&#125;", names, id, username, weight); return successNullDataResult(); &#125;&#125; 使用这种方式解析Properties文件,首先不需要我们自己在强制转换数据类型，也使配置都集中管理，确实是给我们的代码带来更多的可读性，虽然功能简单，但是作用却很大。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Properties</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot中使用@Scheduled执行定时任务]]></title>
    <url>%2F2018%2F01%2F20%2FSpring-Boot%E4%B8%AD%E4%BD%BF%E7%94%A8-Scheduled%E6%89%A7%E8%A1%8C%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[日常工作中，有一些需要定时执行的任务，实现方式有Quartz，SpringTask，Quartz结合数据库使用，可以实现多节点的单实例执行。Spring Boot中也提供定时执行的解决方案@Scheduled。 创建任务 Spring Boot中要想使用@Scheduled，需要在Application中添加@EnableScheduling 1234567891011@SpringBootApplication@EnableTransactionManagement // 开启事务@ComponentScan("com.smart") // 扫描service和controller@MapperScan("com.smart.mapper") // 扫描mapper@EnableAspectJAutoProxy//允许动态代理@EnableSchedulingpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 定义任务 12345678@Service@Slf4jpublic class ScheduledTiming &#123;true@Scheduled(fixedRate = 1000)truepublic void myTask() throws Exception &#123;truetruelog.info("...........定时任务开始执行........");true&#125;&#125; 上面的定时任务，只需要在方法上添加@Scheduled注解，就这么简单，就实现了定时执行，任务的执行周期也可以自定义，固定周期和表达式都支持，详细的可以参考Scheduled的源码1234567891011121314151617181920212223242526272829303132333435//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.springframework.scheduling.annotation;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Repeatable;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(&#123;ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(Schedules.class)public @interface Scheduled &#123; String cron() default ""; String zone() default ""; long fixedDelay() default -1L; String fixedDelayString() default ""; long fixedRate() default -1L; String fixedRateString() default ""; long initialDelay() default -1L; String initialDelayString() default "";&#125; 直接把定时任务的声明和执行周期通过注解的方式实现，的确方便了很多，也省去配置，传统的实现方式往往需要在xml文件中配置task以及task的trigger，Spring Boot的思想是约定由于配置，所以很多地方都是尽量不用配置的方式。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Scheduled</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot中使用@Async实现异步调用]]></title>
    <url>%2F2018%2F01%2F20%2FSpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8%40Async%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在实际项目中，经常需要用到异步处理，大部分情况我们都会使用定义一个线程（Thread），通过ExecutorService来调度，这样实现没有任何问题，那么有没有更简单方便的实现呢？Spring中提供了@Async注解，来简化异步操作。 @Async的定义123456@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Async &#123; String value() default "";&#125; Async的Target包含Method和Type，也就是可以定义在类或者方法上，那么@Async的工作原理是什么样的呢? spring在扫描bean的时候会扫描方法上是否包含@async的注解，如果包含的，spring会为这个bean动态的生成一个子类，我们称之为代理类,代理类继承我们所写的bean的，然后把代理类注入进来，那此时，在执行此方法的时候，会到代理类中，代理类判断了此方法需要异步执行，就不会调用父类(我们原本写的bean)的对应方法。spring自己维护了一个队列，他会把需要执行的方法，放入队列中，等待线程池去读取这个队列，完成方法的执行，从而完成了异步的功能。我们可以关注到再配置task的时候，是有参数让我们配置线程池的数量的。因为这种实现方法，所以在同一个类中的方法调用，添加@async注解是失效的！，原因是当你在同一个类中的时候，方法调用是在类体内执行的，spring无法截获这个方法调用。 @Async的使用 使用@Async很简单，只需要在方法上加上注解即可，方法可以定义2种，有返回值和没有返回值得，有的时候我们还是希望获取该异步任务的返回值123456789101112131415161718192021222324252627282930313233343536373839import org.springframework.scheduling.annotation.Async;import org.springframework.scheduling.annotation.AsyncResult;import org.springframework.stereotype.Component;import java.util.Random;import java.util.concurrent.Future;import lombok.extern.slf4j.Slf4j;/** * 基于Async注解的异步任务，需要开启@EnableAsync * Author: gaowenming * Description: * Date: Created in 20:49 2017/7/2. */@Component@Slf4jpublic class AsyncTask &#123; private static Random random = new Random(); @Async public Future&lt;String&gt; task1() throws Exception &#123; System.out.println("开始做任务一"); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println("完成任务一，耗时：" + (end - start) + "毫秒"); return new AsyncResult&lt;&gt;("任务一完成"); &#125; @Async("smartExecutor") public void taskAsync1() throws Exception &#123; Thread.sleep(1000); for (int i = 0; i &lt; 10; i++) &#123; log.info("##########################" + i); &#125; &#125;&#125; 上面的实例中，我们定义了2个方法，在执行异步操作时，我们还可以指定线程池，@Async(“smartExecutor”)，smartExecutor是我们定义的线程池123456789101112131415161718192021222324252627282930313233/** * 定义线程池 */@Configuration@EnableAsyncpublic class ThreadExecutorConfig &#123; /** * Set the ThreadPoolExecutor's core pool size. */ private static final int corePoolSize = 10; /** * Set the ThreadPoolExecutor's maximum pool size. */ private static final int maxPoolSize = 200; /** * Set the capacity for the ThreadPoolExecutor's BlockingQueue. */ private static final int queueCapacity = 10; @Bean public Executor smartExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(corePoolSize); executor.setMaxPoolSize(maxPoolSize); executor.setQueueCapacity(queueCapacity); executor.setThreadNamePrefix("smartExecutor-"); executor.initialize(); return executor; &#125;&#125; 这里需要注意的是，在SpringBoot中，要启用@Async注解，还需要在config上加上@EnableAsync注解，表示启用@Async注解 线程池和异步方法定义好之后，接下来就是调用，我们可以和普通方法一样12345678910111213141516171819@RestController@RequestMapping("api/task/")@Slf4j@Apipublic class TaskController extends BaseController &#123; @Autowired private AsyncTask asyncTask; @RequestMapping(value = "/async", method = RequestMethod.GET) public BaseJsonResult task1() throws Exception &#123; log.info("test async................"); asyncTask.task1(); asyncTask.taskAsync1(); return successNullDataResult(); &#125;&#125; 是不是很方便，在需要异步操作的时候，终于不用再自己创建Thread了，而且也可以在方法上加上参数，和普通方法一样，很大的增加了代码的可读性。 注意的问题 在实际的开发中，其实我们可以把需要异步操作的方法定义公共的类中，也可以给不同的操作指定不同的线程池，那么如果在异步操作中发生异常该如何处理呢？Spring提供了AsyncUncaughtExceptionHandler这个Handler来处理，我们可以在发生异常的时候，根据不同操作的定义不同的处理机制。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊Dubbo接口授权]]></title>
    <url>%2F2018%2F01%2F19%2F%E8%81%8A%E8%81%8ADubbo%E6%8E%A5%E5%8F%A3%E6%8E%88%E6%9D%83%2F</url>
    <content type="text"><![CDATA[上一篇博客讲了如何使用Dubbo的Filter实现日志追踪，其实Filter的功能有很多，今天讲讲如何使用Filter实现Dubbo的接口授权 Dubbo本身是没有授权机制的，所以需要我们自己实现，具体的实现方案如下： 授权的粒度，主要有如下几种：1、全部接口2、部分接口3、单个接口 授权服务本身的稳定性也是十分重要的，不要因为授权服务的不可用造成正常业务的瘫痪。伪代码如下：123456789101112public class AuthFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; if (success) &#123; return invoker.invoke(invocation); &#125; else &#123; // TODO 错误处理 &#125; &#125;&#125; 原理也很简单，在执行invoke之前先对consumer的请求做校验，首先dubbo调用时，公共参数都是可以获取的，比如方法名称，consumer端的名称等，当然还可以通过下发appId的方式，来区分调用端123456789public class ConsumerContextFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 设置appId RpcContext.getContext().setAttachment("appId", appId); // 执行接口 return invoker.invoke(invocation); &#125;&#125; consumer端把自身的appid传到provider，provider会根据appid来区分不同调用的权限 Dubbo的Filter用处确实很多，而且使用也很方便，通过2篇文章讲解了日志和权限的应用，能够在不侵入业务的情况下完成既定的功能，非常灵活。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Dubbo的分布式日志追踪]]></title>
    <url>%2F2017%2F12%2F30%2F%E5%9F%BA%E4%BA%8EDubbo%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%97%A5%E5%BF%97%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[之前讲过单系统中的日志追踪，现在系统设计都是往服务化的方向发展，一个大型项目被拆分成多个服务，服务之间互相调用。拆分的服务越多，服务之间的关系越复杂，日志的追踪就更加困难。那么RPC之间怎么做到日志追踪呢，本文就介绍下基于Dubbo的日志追踪。 Dubbo的Filter接口我们需要先介绍下Dubbo的Filter接口12345678package com.alibaba.dubbo.rpc;import com.alibaba.dubbo.common.extension.SPI;@SPIpublic interface Filter &#123; Result invoke(Invoker&lt;?&gt; var1, Invocation var2) throws RpcException;&#125; 接口的定义很简单，只有一个invoke方法，由此就可以得到我们的实现思路，在Dubbo的调用端生成traceId，在调用的时候把该traceId传递到服务端，服务端拿到这个traceId，用该traceId作为本次调用的追踪id，Dubbo也提供了RpcContext类，用于Consumer到Provider的参数传递12345678910111213141516public class RpcContext &#123; private static final ThreadLocal&lt;RpcContext&gt; LOCAL = new ThreadLocal&lt;RpcContext&gt;() &#123; protected RpcContext initialValue() &#123; return new RpcContext(); &#125; &#125;; private Future&lt;?&gt; future; private List&lt;URL&gt; urls; private URL url; private String methodName; private Class&lt;?&gt;[] parameterTypes; private Object[] arguments; private InetSocketAddress localAddress; private InetSocketAddress remoteAddress; private final Map&lt;String, String&gt; attachments = new HashMap(); private final Map&lt;String, Object&gt; values = new HashMap(); RpcContext中有attachments属性，参数可以通过key-value的形式传递 Consumer端生成traceId12345678910111213public class TraceFilter implements Filter &#123; private static Logger LOGGER = LoggerFactory.getLogger(TraceFilter.class); @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; RpcContext context = RpcContext.getContext(); String chTraceId = MDC.get("traceID"); LOGGER.debug("chTraceId=&#123;&#125;", chTraceId); context.setAttachment("chTraceId", chTraceId); return invoker.invoke(invocation); &#125;&#125; 调用端发起请求前，往RpcContext中加入我们自己定义的traceId Provider端接收traceId12345678910111213141516171819public class TraceFilter implements Filter &#123; private static Logger LOGGER = LoggerFactory.getLogger(TraceFilter.class); @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; RpcContext context = RpcContext.getContext(); String chTraceId = context.getAttachment("chTraceId") + "&amp;client=" + context.getRemoteAddressString(); LOGGER.debug("chTraceId=&#123;&#125;", chTraceId); if (StringUtils.isNotEmpty(chTraceId)) &#123; MDC.put("traceID", chTraceId); &#125; Result result = invoker.invoke(invocation); if (StringUtils.isNotEmpty(chTraceId)) &#123; MDC.clear(); &#125; return result; &#125;&#125; 服务提供端收到traceId，然后使用该id做为后续整个接口链路的日志追踪id实现其实很简单，只需要分别在服务的2端实现Filter接口，使用RpcContext发送和接收参数最后还需在resource目录下定义自己的Filter，新建META-INF\dubbo目录，定义一个文件，文件名：com.alibaba.dubbo.rpc.Filter，里面增加一行自己定义的Filter，内容如下：traceFilter=com.wlqq.ms.filter.TraceFilter详细的配置可以参考Dubbo的官方说明文档：http://dubbo.io/books/dubbo-user-book/demos/attachment.html 总结分布式链路追踪其实是一个复杂的项目，本文只是一个简单的实现，Google提出了dapper论文，Twitter开源的Zipkin，后面会介绍下Zipkin的使用，也打算在项目中引入Zipkin，毕竟现在这种实现还是无法满足复杂的场景。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用MDC追踪系统日志]]></title>
    <url>%2F2017%2F12%2F30%2F%E4%BD%BF%E7%94%A8MDC%E8%BF%BD%E8%B8%AA%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[在系统开发中，日志必不可少，前段时间我们还因为在线上开启Debug而造成系统故障，所以日志的处理应该让我们更加重视。在线上系统，日志很多，接口之间的日志错乱交替的打印，大大的影响了我们对日志的跟踪，我们要想跟踪一次请求的完整日志，好像都只能通过时间、线程名等信息，但是也无法精确的找出。MDC的出现，完美的解决了这个棘手的问题。 什么是MDC MDC ( Mapped Diagnostic Contexts )，是SLF4J中提供的一个类，专门用来跟踪请求链路的日志123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.slf4j;import java.io.Closeable;import java.util.Map;import org.slf4j.helpers.NOPMDCAdapter;import org.slf4j.helpers.Util;import org.slf4j.impl.StaticMDCBinder;import org.slf4j.spi.MDCAdapter;public class MDC &#123; static final String NULL_MDCA_URL = "http://www.slf4j.org/codes.html#null_MDCA"; static final String NO_STATIC_MDC_BINDER_URL = "http://www.slf4j.org/codes.html#no_static_mdc_binder"; static MDCAdapter mdcAdapter; private MDC() &#123; &#125; private static MDCAdapter bwCompatibleGetMDCAdapterFromBinder() throws NoClassDefFoundError &#123; try &#123; return StaticMDCBinder.getSingleton().getMDCA(); &#125; catch (NoSuchMethodError var1) &#123; return StaticMDCBinder.SINGLETON.getMDCA(); &#125; &#125; public static void put(String key, String val) throws IllegalArgumentException &#123; if (key == null) &#123; throw new IllegalArgumentException("key parameter cannot be null"); &#125; else if (mdcAdapter == null) &#123; throw new IllegalStateException("MDCAdapter cannot be null. See also http://www.slf4j.org/codes.html#null_MDCA"); &#125; else &#123; mdcAdapter.put(key, val); &#125; &#125; public static MDC.MDCCloseable putCloseable(String key, String val) throws IllegalArgumentException &#123; put(key, val); return new MDC.MDCCloseable(key); &#125; public static String get(String key) throws IllegalArgumentException &#123; if (key == null) &#123; throw new IllegalArgumentException("key parameter cannot be null"); &#125; else if (mdcAdapter == null) &#123; throw new IllegalStateException("MDCAdapter cannot be null. See also http://www.slf4j.org/codes.html#null_MDCA"); &#125; else &#123; return mdcAdapter.get(key); &#125; &#125; public static void remove(String key) throws IllegalArgumentException &#123; if (key == null) &#123; throw new IllegalArgumentException("key parameter cannot be null"); &#125; else if (mdcAdapter == null) &#123; throw new IllegalStateException("MDCAdapter cannot be null. See also http://www.slf4j.org/codes.html#null_MDCA"); &#125; else &#123; mdcAdapter.remove(key); &#125; &#125; public static void clear() &#123; if (mdcAdapter == null) &#123; throw new IllegalStateException("MDCAdapter cannot be null. See also http://www.slf4j.org/codes.html#null_MDCA"); &#125; else &#123; mdcAdapter.clear(); &#125; &#125; public static Map&lt;String, String&gt; getCopyOfContextMap() &#123; if (mdcAdapter == null) &#123; throw new IllegalStateException("MDCAdapter cannot be null. See also http://www.slf4j.org/codes.html#null_MDCA"); &#125; else &#123; return mdcAdapter.getCopyOfContextMap(); &#125; &#125; public static void setContextMap(Map&lt;String, String&gt; contextMap) &#123; if (mdcAdapter == null) &#123; throw new IllegalStateException("MDCAdapter cannot be null. See also http://www.slf4j.org/codes.html#null_MDCA"); &#125; else &#123; mdcAdapter.setContextMap(contextMap); &#125; &#125; public static MDCAdapter getMDCAdapter() &#123; return mdcAdapter; &#125; static &#123; try &#123; mdcAdapter = bwCompatibleGetMDCAdapterFromBinder(); &#125; catch (NoClassDefFoundError var2) &#123; mdcAdapter = new NOPMDCAdapter(); String msg = var2.getMessage(); if (msg == null || !msg.contains("StaticMDCBinder")) &#123; throw var2; &#125; Util.report("Failed to load class \"org.slf4j.impl.StaticMDCBinder\"."); Util.report("Defaulting to no-operation MDCAdapter implementation."); Util.report("See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details."); &#125; catch (Exception var3) &#123; Util.report("MDC binding unsuccessful.", var3); &#125; &#125; public static class MDCCloseable implements Closeable &#123; private final String key; private MDCCloseable(String key) &#123; this.key = key; &#125; public void close() &#123; MDC.remove(this.key); &#125; &#125;&#125; MDC中提供的全是静态方法，实现的核心是MDCAdapter，从命名方式，我们不难理解，这是适配器，这也是SLF4J的核心，提供适配器，具体的实现有Log4j或者LogBack。12345678910111213141516171819202122//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.slf4j.spi;import java.util.Map;public interface MDCAdapter &#123; void put(String var1, String var2); String get(String var1); void remove(String var1); void clear(); Map&lt;String, String&gt; getCopyOfContextMap(); void setContextMap(Map&lt;String, String&gt; var1);&#125; 我们使用的Logback，其中对MDCAdapter接口有具体的实现类LogbackMDCAdapter 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package ch.qos.logback.classic.util;import java.util.Collections;import java.util.HashMap;import java.util.Map;import java.util.Set;import org.slf4j.spi.MDCAdapter;public class LogbackMDCAdapter implements MDCAdapter &#123; final ThreadLocal&lt;Map&lt;String, String&gt;&gt; copyOnThreadLocal = new ThreadLocal(); private static final int WRITE_OPERATION = 1; private static final int MAP_COPY_OPERATION = 2; final ThreadLocal&lt;Integer&gt; lastOperation = new ThreadLocal(); public LogbackMDCAdapter() &#123; &#125; private Integer getAndSetLastOperation(int op) &#123; Integer lastOp = (Integer)this.lastOperation.get(); this.lastOperation.set(op); return lastOp; &#125; private boolean wasLastOpReadOrNull(Integer lastOp) &#123; return lastOp == null || lastOp.intValue() == 2; &#125; private Map&lt;String, String&gt; duplicateAndInsertNewMap(Map&lt;String, String&gt; oldMap) &#123; Map&lt;String, String&gt; newMap = Collections.synchronizedMap(new HashMap()); if (oldMap != null) &#123; synchronized(oldMap) &#123; newMap.putAll(oldMap); &#125; &#125; this.copyOnThreadLocal.set(newMap); return newMap; &#125; public void put(String key, String val) throws IllegalArgumentException &#123; if (key == null) &#123; throw new IllegalArgumentException("key cannot be null"); &#125; else &#123; Map&lt;String, String&gt; oldMap = (Map)this.copyOnThreadLocal.get(); Integer lastOp = this.getAndSetLastOperation(1); if (!this.wasLastOpReadOrNull(lastOp) &amp;&amp; oldMap != null) &#123; oldMap.put(key, val); &#125; else &#123; Map&lt;String, String&gt; newMap = this.duplicateAndInsertNewMap(oldMap); newMap.put(key, val); &#125; &#125; &#125; public void remove(String key) &#123; if (key != null) &#123; Map&lt;String, String&gt; oldMap = (Map)this.copyOnThreadLocal.get(); if (oldMap != null) &#123; Integer lastOp = this.getAndSetLastOperation(1); if (this.wasLastOpReadOrNull(lastOp)) &#123; Map&lt;String, String&gt; newMap = this.duplicateAndInsertNewMap(oldMap); newMap.remove(key); &#125; else &#123; oldMap.remove(key); &#125; &#125; &#125; &#125; public void clear() &#123; this.lastOperation.set(Integer.valueOf(1)); this.copyOnThreadLocal.remove(); &#125; public String get(String key) &#123; Map&lt;String, String&gt; map = (Map)this.copyOnThreadLocal.get(); return map != null &amp;&amp; key != null ? (String)map.get(key) : null; &#125; public Map&lt;String, String&gt; getPropertyMap() &#123; this.lastOperation.set(Integer.valueOf(2)); return (Map)this.copyOnThreadLocal.get(); &#125; public Set&lt;String&gt; getKeys() &#123; Map&lt;String, String&gt; map = this.getPropertyMap(); return map != null ? map.keySet() : null; &#125; public Map&lt;String, String&gt; getCopyOfContextMap() &#123; Map&lt;String, String&gt; hashMap = (Map)this.copyOnThreadLocal.get(); return hashMap == null ? null : new HashMap(hashMap); &#125; public void setContextMap(Map&lt;String, String&gt; contextMap) &#123; this.lastOperation.set(Integer.valueOf(1)); Map&lt;String, String&gt; newMap = Collections.synchronizedMap(new HashMap()); newMap.putAll(contextMap); this.copyOnThreadLocal.set(newMap); &#125;&#125; 从源码中看出，核心思想还是ThreadLocal1234final ThreadLocal&lt;Map&lt;String, String&gt;&gt; copyOnThreadLocal = new ThreadLocal();private static final int WRITE_OPERATION = 1;private static final int MAP_COPY_OPERATION = 2;final ThreadLocal&lt;Integer&gt; lastOperation = new ThreadLocal(); 定义了2个ThreadLocal，一个维护着Map，这就是我们在使用时自己定义的追踪数据，另一个ThreadLocal记录着该线程的操作记录，需要注意，在上面的代码中，write操作即put会去修改lastOperation，而get操作则不会。这样就保证了，只会在第一次写时复制。 MDC的使用定义全局拦截器 MDC的使用很简单，只需要调用put方法就行，MDC.put(“traceId”, “traceId”),再结合HandlerInterceptor的使用，可以在所有的请求中都加上日志追踪，就无需手动在每个请求中加了。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.smart.server.interceptor;import org.slf4j.MDC;import org.springframework.web.method.HandlerMethod;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import java.lang.reflect.Method;import java.util.UUID;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import lombok.extern.slf4j.Slf4j;/** * ClassName: TimeHandlerInterceptor &lt;br/&gt; Function: 方法执行时间拦截器. &lt;br/&gt; date: 2017年3月23日 下午8:46:58 * &lt;br/&gt; * * author gaowenming since JDK 1.8 */@Slf4jpublic class TimeHandlerInterceptor implements HandlerInterceptor &#123; // 当前时间戳 private ThreadLocal&lt;Long&gt; threadLocalTime = new ThreadLocal&lt;&gt;(); /** * controller 执行之前调用 */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //日志追加traceId追踪 MDC.put("traceId", "traceId=" + UUID.randomUUID().toString().replace("-", "")); long startTime = System.currentTimeMillis(); threadLocalTime.set(startTime); return true; &#125; /** * controller 执行之后，且页面渲染之前调用 */ @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); long endTime = System.currentTimeMillis(); long startTime = threadLocalTime.get(); long executeTime = endTime - startTime; log.info("[&#123;&#125;.&#123;&#125;] 执行耗时:&#123;&#125;ms", method.getDeclaringClass().getName(), method.getName(), executeTime); &#125; /** * 页面渲染之后调用，一般用于资源清理操作 */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; MDC.clear(); &#125;&#125; 定义一个全局拦截器，拦截所有的Controller请求，在preHandle方法中，调用MDC.put(“traceId”, “traceId=” + UUID.randomUUID().toString().replace(“-“, “”));这样traceId就会被加到该请求所有的链路中，在afterCompletion方法中clear，确保本次请求完成后，MDC中的数据要清空。该拦截器中还加入了方法的执行时间统计，原理和MDC类似，使用ThreadLocal。 修改logback.xml文件 上面我们往MDC中put了traceId的key，再把这个key增加到logback.xml文件中即可12345&lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;pattern&gt;%date %level %X&#123;traceId&#125; [%thread] %logger&#123;50&#125;-[%line] %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; 配置完logback文件后，然后就可以正常打印了 1232017-12-30 10:48:53,986 INFO traceId=73eb01785cce4ce8812dd091b07c2ccd [http-nio-8000-exec-8] 2017-12-30 10:48:53,987 WARN traceId=73eb01785cce4ce8812dd091b07c2ccd [http-nio-8000-exec-8] 2017-12-30 10:48:53,988 ERROR traceId=73eb01785cce4ce8812dd091b07c2ccd [http-nio-8000-exec-8] 到此，MDC的使用就介绍完了，其实总结起来也挺简单的，核心就是ThreadLocal，配置也非常简单，但是功能确很强大，很大的方便了我们对日志的追踪。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>MDC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMvc全局异常处理]]></title>
    <url>%2F2017%2F12%2F28%2FSpringMvc%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[异常处理是开发中不可避免的，好的异常处理方式，能提高代码的可读性，使代码更简洁，本文就介绍下在开发Rest接口时，如何优雅的处理异常。 如何抛出异常 java中异常分为2类：预期异常和运行时异常RuntimeException，预期异常就是需要明确的捕获异常，比如文件读写时，需要捕获IOException。运行时异常，无法预知的异常，比如著名的NullPointException。那么我们在定义接口时，怎么定义异常呢？一个原则，就是尽量在调用的最上层处理。 比如一个调用连中，Http-&gt;Controller-&gt;Service-&gt;Dao-&gt;DB,Controller层负责和调用端的数据交互，一般都会包含请求的响应状态，成功还是失败，返回的数据，通常我们都会定义一个通用的返回体，包含Code，Msg，ResultData，Service层负责具体的业务逻辑，Dao层负责与DB的交互。 正常成功的请求，可以在Controller层定义，但是各种系统的异常情况怎么优雅的处理呢？答案就是抛出异常。我们定义好业务异常(BusinessException),定义好异常code和异常信息Msg，在业务出现异常的情况时，直接抛出异常信息，由Controller层统一处理，Service层只需要在遇到异常时，直接Throw就可以，这样既能阻止程序继续往下执行，也避免了代码中无限的return。 定义业务异常 上面介绍了业务异常通用类，主要包含异常代码，异常信息，具体的定义如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class BusinessException extends RuntimeException &#123; private static final long serialVersionUID = 1L; private BusinessErrorMsg businessErrorMsg; public BusinessException(BusinessErrorMsg businessErrorMsg) &#123; this.businessErrorMsg = BusinessErrorMsg.SYSTEM_ERROR; this.businessErrorMsg = businessErrorMsg; &#125; public BusinessException() &#123; this.businessErrorMsg = BusinessErrorMsg.SYSTEM_ERROR; &#125; public BusinessException(BusinessErrorMsg businessErrorMsg, Throwable cause) &#123; this.businessErrorMsg = BusinessErrorMsg.SYSTEM_ERROR; this.businessErrorMsg = businessErrorMsg; &#125; public BusinessException(String message, Throwable cause) &#123; super(message, cause); this.businessErrorMsg = BusinessErrorMsg.SYSTEM_ERROR; &#125; public BusinessException(String message) &#123; super(message); this.businessErrorMsg = BusinessErrorMsg.SYSTEM_ERROR; &#125; protected BusinessException(String message, Throwable cause, boolean enableSuppression, boolean writableStackTrace) &#123; super(message, cause, enableSuppression, writableStackTrace); this.businessErrorMsg = BusinessErrorMsg.SYSTEM_ERROR; &#125; public BusinessException(Throwable cause) &#123; super(cause); this.businessErrorMsg = BusinessErrorMsg.SYSTEM_ERROR; &#125; public BusinessErrorMsg getBusinessErrorMsg() &#123; return this.businessErrorMsg; &#125; public void setBusinessErrorMsg(BusinessErrorMsg businessErrorMsg) &#123; this.businessErrorMsg = businessErrorMsg; &#125;&#125; 异常代码我们使用枚举的方式12345678910111213141516171819202122232425262728293031package com.smart.service.base;public enum BusinessErrorMsg &#123; SYSTEM_ERROR(Integer.valueOf(9999), "系统错误"), VALIDATION_TOKEN_NULL(Integer.valueOf(1000), "token is null"), VALIDATION_PARAM_ERROR(Integer.valueOf(1001), "参数错误"); private Integer errorCode = Integer.valueOf(9999); private String errorMessage = "系统错误"; private BusinessErrorMsg(Integer errorCode, String errorMessage) &#123; this.errorCode = errorCode; this.errorMessage = errorMessage; &#125; public Integer getErrorCode() &#123; return this.errorCode; &#125; public void setErrorCode(Integer errorCode) &#123; this.errorCode = errorCode; &#125; public String getErrorMessage() &#123; return this.errorMessage; &#125; public void setErrorMessage(String errorMessage) &#123; this.errorMessage = errorMessage; &#125;&#125; 使用枚举的好处就是比较直观，code和msg一一对应 全局异常处理异常定义好了，那怎么能优雅的捕获呢？SpringMvc提供了全局RestControllerAdvice，顾名思义，RestController的拦截器，使用这种方式，我们就不用在Controller层使用try/catch了，直接交给异常处理器就ok了，是不是很方便呢。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.smart.server.handler;import com.smart.server.base.BaseJsonResult;import com.smart.service.base.BusinessErrorMsg;import com.smart.service.base.BusinessException;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.bind.annotation.RestControllerAdvice;import java.util.Arrays;import java.util.Map;import javax.servlet.http.HttpServletRequest;import lombok.extern.slf4j.Slf4j;/** * 全局异常处理 * * 2017年4月28日 下午10:14:26 &lt;br/&gt; * * author gaowenming version since JDK 1.8 */@RestControllerAdvice@Slf4jpublic class GlobalExceptionHandler &#123; /** * 系统异常 * * @author gaowenming param req param e return throws Exception since JDK 1.8 */ @ExceptionHandler(value = Exception.class) @ResponseBody public BaseJsonResult&lt;Object&gt; defaultExceptionHandler(HttpServletRequest req, Exception e) throws Exception &#123; log.error("&lt;-----------------系统响应异常-----------------&gt;", e); printMethodParameters(req); BaseJsonResult&lt;Object&gt; baseJsonResult = new BaseJsonResult&lt;&gt;(); baseJsonResult.setStatus(HttpStatus.INTERNAL_SERVER_ERROR.value()); baseJsonResult.setMsg("请求失败,请稍后重试！"); return baseJsonResult; &#125; /** * 业务异常 * * @author gaowenming param req param e return throws Exception since JDK 1.8 */ @ExceptionHandler(value = BusinessException.class) @ResponseBody public BaseJsonResult&lt;Object&gt; smartBusinessExceptionHandler(HttpServletRequest req, BusinessException e) throws Exception &#123; BaseJsonResult&lt;Object&gt; baseJsonResult = new BaseJsonResult&lt;&gt;(); BusinessErrorMsg businessErrorMsg = e.getBusinessErrorMsg(); log.warn("catch BusinessException,code:&#123;&#125;,message:&#123;&#125;", businessErrorMsg.getErrorCode(), businessErrorMsg.getErrorMessage()); printMethodParameters(req); baseJsonResult.setStatus(businessErrorMsg.getErrorCode()); baseJsonResult.setMsg(businessErrorMsg.getErrorMessage()); return baseJsonResult; &#125; /** * 记录方法的入参 */ private static void printMethodParameters(HttpServletRequest request) &#123; StringBuilder methodInfo = new StringBuilder(); methodInfo.append("url=").append(request.getServletPath()); methodInfo.append(" ;params= "); if (request.getQueryString() != null) &#123; methodInfo.append(request.getQueryString()).append(" - "); &#125; else &#123; Map&lt;String, String[]&gt; parameters = request.getParameterMap(); if (parameters.size() != 0) &#123; methodInfo.append(" ["); &#125; for (Map.Entry&lt;String, String[]&gt; entry : parameters.entrySet()) &#123; String key = entry.getKey(); Object value = entry.getValue(); String message = ""; if (value.getClass().isArray()) &#123; Object[] args = (Object[]) value; message = " " + key + "=" + Arrays.toString(args) + " "; &#125; else &#123; message = key + "=" + String.valueOf(value) + " "; &#125; methodInfo.append(message); &#125; if (parameters.size() != 0) &#123; methodInfo.append("]"); &#125; &#125; log.info(methodInfo.toString()); &#125;&#125; 定义GlobalExceptionHandler，加上@RestControllerAdvice注解，这样就表示拦截Controller所有的异常情况了，我们可以使用@ExceptionHandler注解，处理不同类型的异常。推荐大家把异常发生时的入参都打印出来，这样能够方便我们在出现异常时快速的定位问题。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>异常处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于注解的Token校验方案]]></title>
    <url>%2F2017%2F12%2F26%2F%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84Token%E6%A0%A1%E9%AA%8C%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[在后端开发中，通常需要对接口做权限校验，校验用户是否需要登录，是否需要认证等等，本文就来介绍下如何通过注解的方式来对Token做认证 注解定义 其实说到用户认证，大家脑海中肯定会想到拦截器（Interceptor）和过滤器（Filter），那么怎样才能更灵活的实现呢？注解毫无疑问就派上用场了。 首先定义注解：1234567891011121314151617package com.smart.server.annotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * token注解，可用于类、方法中，拦截token验证 * * Created by gaowenming on 2017/6/15. */@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface TokenValidation &#123; String name() default "";&#125; 定义一个注解TokenValidation，Target的作用范围是TYPE和METHOD，也就是可以在Class类上，也可以在方法上，如果是在类上使用注解，表示该类所有的方法都需要进行Token的校验，如果在方法上，表示该方法需要进行认证。 注解实现 注解定义好了,我们基于AOP的方式，对注解进行拦截123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import com.smart.server.util.Constants;import com.smart.service.base.BusinessErrorMsg;import com.smart.service.base.BusinessException;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;import org.springframework.util.StringUtils;import org.springframework.web.context.request.RequestAttributes;import org.springframework.web.context.request.RequestContextHolder;import org.springframework.web.context.request.ServletRequestAttributes;import javax.servlet.http.HttpServletRequest;import lombok.extern.slf4j.Slf4j;/** * Created by gaowenming on 2017/6/15. */@Aspect@Component@Slf4jpublic class TokenValidationInterceptor &#123; //注解在类上面@within @Pointcut("@within(com.smart.server.annotation.TokenValidation)") public void pointcut() &#123; &#125; @Before("pointcut()") public void tokenValidationType(JoinPoint point) throws Throwable &#123; commonTokenValidation(point); &#125; //注解在方法上面@annotation @Pointcut("@annotation(com.smart.server.annotation.TokenValidation)") public void pointcutMethod() &#123; &#125; @Before("pointcutMethod()") public void tokenValidationMethod(JoinPoint point) throws Throwable &#123; commonTokenValidation(point); &#125; //公共的校验 public static void commonTokenValidation(JoinPoint point) throws Throwable &#123; HttpServletRequest request; RequestAttributes ra = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes sra = (ServletRequestAttributes) ra; request = sra.getRequest(); String url = request.getServletPath(); String token = request.getHeader(Constants.TOKEN_NAME); log.info("TokenHandlerInterceptor----- url:&#123;&#125;,token:&#123;&#125; ", url, token); if (StringUtils.isEmpty(token)) &#123; throw new BusinessException(BusinessErrorMsg.VALIDATION_TOKEN_NULL); &#125; //校验token是否过期和正确 //TODO &#125;&#125; 上面的实现，做个简单的说明，首先我们约定好，token封装在Http请求的Header中，拦截器上中先从Header中获取token的值，然后判断token是否为空，如果不为空，还需要判断token是否过期，是否正确。在实际项目中，用户登录后，服务端会根据一定的算法计算出token的值，然后把该token的值放入Redis中，并设置有效期，这样就很方便的处理过期的问题。 注解使用经过上面的2步，就可以在我们定义的Controller中使用我们定义的注解了12345678910111213141516171819202122232425262728293031323334353637383940414243package com.smart.server.controller;import com.smart.model.Dic;import com.smart.server.annotation.TokenValidation;import com.smart.server.base.BaseController;import com.smart.server.base.BaseJsonResult;import com.smart.service.IDicService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RestController;import io.swagger.annotations.Api;import lombok.extern.slf4j.Slf4j;@RestController@RequestMapping("api/dic/")@Api@Slf4jpublic class DicController extends BaseController &#123; @Autowired private IDicService dicService; @RequestMapping(value = "/&#123;id&#125;", method = RequestMethod.GET) public BaseJsonResult&lt;Dic&gt; getDic(@PathVariable Integer id) throws Exception &#123; log.info("getDic......."); Dic dic = dicService.get(id); return successResult(dic); &#125; @RequestMapping(value = "/addDic", method = RequestMethod.POST) @TokenValidation public BaseJsonResult addDic(@RequestBody Dic dic) throws Exception &#123; log.info("addDic......."); dicService.save(dic); return successNullDataResult(); &#125;&#125; 是不是很方便，get操作不需要校验，就无需增加注解，在add操作中，增加token校验，加上注解即可。 为什么用注解 使用注解的方式，你会发现非常灵活，类和方法可以自己灵活设置，处理逻辑使用AOP的方式统一处理。其实还有其他的一些使用场景，比如有些接口返回值需要加密返回，也可以使用类似的注解方式实现。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis解决定时任务在分布式环境单节点执行]]></title>
    <url>%2F2017%2F12%2F24%2FRedis%E8%A7%A3%E5%86%B3%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%9C%A8%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E5%8D%95%E8%8A%82%E7%82%B9%E6%89%A7%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[定时任务，在日常开发中是经常用到的，在分布式环境中，定时任务的执行往往需要控制多节点同时执行的问题，比如可以借助Quartz，或者分布式锁，本文提供另一种解决方式，也是借助Redis。 实现方式 在Redis中，提供了自增和增减的相关命令，来保证计数的原子性 incr 递增1并返回递增后的结果；incrby 根据指定值做递增或递减操作并返回递增或递减后的结果(incrby递增或递减取决于传入值的正负)decr 递减1并返回递减后的结果；decrby 根据指定值做递增或递减操作并返回递增或递减后的结果(decrby递增或递减取决于传入值的正负) 了解了上面几个命令之后，在来说通过计数器来控制并发执行，应该就很容易理解了直接上代码吧：1234567long jobKeyValue = redisKeyValueResolver.increment(ExdataConstants.JOB_KEY);LOGGER.debug("jobKeyIncrementAfterValue:&#123;&#125;", jobKeyValue); if (jobKeyValue == 1) &#123; //一秒失效 redisKeyValueResolver.expireKey(ExdataConstants.JOB_KEY, 1); //业务逻辑。。。 &#125; 上面一段代码，首先定义一个key，当定时任务触发时，多个节点同时执行incr自增操作,第一个执行自增的节点的值就是1，其他的节点就是2、3、4…根据自增后的值来控制定时任务的执行，也就可以有效的控制只执行一次了。 当然还是需要注意，一定要在if语句块最前面执行expire操作，因为执行业务逻辑需要时间，更有可能出现异常，所以在最前面设置过期时间，保证了下次定时任务执行时，key已失效。 不需要使用较重的分布式锁，巧妙的运用了Redis的原子操作，这样是的实现方式是不是更简单呢?]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Log4j的debug日志引起的线上故障]]></title>
    <url>%2F2017%2F12%2F22%2FLog4j%E7%9A%84debug%E6%97%A5%E5%BF%97%E5%BC%95%E8%B5%B7%E7%9A%84%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%2F</url>
    <content type="text"><![CDATA[前天下午，运维突然在微信群里说系统流量下跌了，报警邮件也马上来了，都是api接口的time out，查看各种监控工具，zabbix，oneapm，es集群，除了发现流量有下跌，没有别的异常情况。 错误现象 入口流量没有明显增加查看了流量监控，入口流量并没有出现爆发式的增长，很平稳，毕竟我们的流量高峰是在上午，下午3点很难出现高峰 内存、CPU没有明显波动查看系统的运行状态，内存、CPU都没有出现大的波动，说明并没有出现大的计算任务，如果有计算型的任务，会消耗大量的内存和CPU资源 线程数上升迅猛看监控，配置的Tomcat的线程池满了，直接导致了系统的请求超时。[图片] 异常原因分析 既然已经确认是由于线程池的堆积，造成系统的调用超时，那么为什么会突然之间线程池暴涨呢？原因竟然是由于一个同事开启了线上的debug日志跟踪一个问题，持续时间大概20分钟，那么问题来了，log4j开启debug日志，为什么会导致线程池暴涨，造成系统崩溃呢？ 由于log4j同步打日志，当debug日志过多时，频繁的写磁盘文件，api请求的耗时就会增加，那么该api占用的线程的时间就会变长，当占用时间过长，导致线程池不够时，就会出现等待的情况，持续时间一长，等待的线程越来越多，那么就会出现time out了 如何解决 规范日志的打印日志打印不是越多越好，其实只要关键位置的日志往往就可以，比如方法的入口和出口，逻辑的分叉，try/catch的异常日志 异常信息的拼装往往debug的时候，打印日志都是很详细的，比如某个对象的完整信息，Http的完整响应等，这些信息都是比较大的，这时候如果用log.debug(Json.toJSONString(user));也许你觉得这么写也没有什么问题啊，其实不然，虽然如果你设置info级别，这个debug日志是不会打印，但是它会执行Json的转换，这其实也是损耗性能的，系统的性能往往就是细节地方不注意，累计多了，就会出现瓶颈。这时，可以使用级别判断来解决这个问题 if(log.isDebugEnable) { LOG.debug(“params = {}”, JSON.toJSONString(user)); } 可以采用logback、log4j2来替换log4j。log4j2已经发行了稳定版本，logback是基于slf4j的门面实现，性能都比log4j高不少]]></content>
      <categories>
        <category>故障分析</category>
      </categories>
      <tags>
        <tag>Log4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装Docker]]></title>
    <url>%2F2017%2F12%2F05%2FCentos7%E5%AE%89%E8%A3%85Docker%2F</url>
    <content type="text"><![CDATA[在工作中,总是避免不了搭建各种开发环境，配置各种组件的环境变量，如果你厌倦了以往的方式，你可以尝试使用Docker，本文就从Docker的安装开始。 安装说明 Docker支持以下的CentOS版本：CentOS 7 (64-bit)CentOS 6.5 (64-bit) 或更高的版本前提条件目前，CentOS 仅发行版本中的内核支持 Docker。Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。 yum安装docker 1.使用root权限登陆系统。 2.更新系统包到最新。 yum -y update 3、安装docker yum -y install docker 4、启动docker服务 systemctl start docker.service 5、创建开机启动Docker服务 systemctl enable docker.service 6、查看Docker版本号 docker version 7、运行hello-world docker run hello-world 后续后续的组件，我会尽量用Docker的方式来处理，这样既方便快捷，也完美的解决了一台机器中安装某个服务的多个版本，比如es，redis，后面也会在使用中总结更多的用法。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Centos</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SimpleDateFormat的线程安全问题]]></title>
    <url>%2F2017%2F11%2F26%2FSimpleDateFormat%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[SimpleDateFormat在进行日期格式转换时用的很多，但是 DateFormat 和 SimpleDateFormat 类不都是线程安全的，在多线程环境下调用 format() 和 parse() 方法应该使用同步代码来避免问题 多线程测试12345678910111213141516 * &lt;p&gt; * Date formats are not synchronized. * It is recommended to create separate format instances for each thread. * If multiple threads access a format concurrently, it must be synchronized * externally. * * @see &lt;a href="http://java.sun.com/docs/books/tutorial/i18n/format/simpleDateFormat.html"&gt;Java Tutorial&lt;/a&gt; * @see java.util.Calendar * @see java.util.TimeZone * @see DateFormat * @see DateFormatSymbols * @author Mark Davis, Chen-Lieh Huang, Alan Liu */public class SimpleDateFormat extends DateFormat &#123;...................｝ 在注视中，明确说明If multiple threads access a format concurrently, it must be synchronized测试代码：12345678910111213141516171819202122public static final String PATTEN = "yyyy-MM-dd hh:mm:ss"; public static final SimpleDateFormat sdf = new SimpleDateFormat(PATTEN); public static final CountDownLatch countDownLatch = new CountDownLatch(100); @Test public void testJDKSimpleDateFormat() &#123; //jdk的实现方式，会有线程安全的问题 for (int i = 0; i &lt; 100; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(sdf.parseObject("2013-05-24 06:02:20")); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125; 上面的测试方法在多线程下会出现如下异常：123456789101112131415161718192021222324252627282930313233343536Exception in thread "Thread-1" Exception in thread "Thread-3" java.lang.NumberFormatException: For input string: ""trueat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)trueat java.lang.Long.parseLong(Long.java:453)trueat java.lang.Long.parseLong(Long.java:483)trueat java.text.DigitList.getLong(DigitList.java:194)trueat java.text.DecimalFormat.parse(DecimalFormat.java:1316)trueat java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1793)trueat java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1455)trueat java.text.DateFormat.parseObject(DateFormat.java:415)trueat java.text.Format.parseObject(Format.java:243)trueat com.smart.tools.SimpleDateFormatTest$1.run(SimpleDateFormatTest.java:32)trueat java.lang.Thread.run(Thread.java:745)Exception in thread "Thread-8" java.lang.NumberFormatException: For input string: ""trueat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)trueat java.lang.Long.parseLong(Long.java:453)trueat java.lang.Long.parseLong(Long.java:483)trueat java.text.DigitList.getLong(DigitList.java:194)trueat java.text.DecimalFormat.parse(DecimalFormat.java:1316)trueat java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:2088)trueat java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1455)trueat java.text.DateFormat.parseObject(DateFormat.java:415)trueat java.text.Format.parseObject(Format.java:243)trueat com.smart.tools.SimpleDateFormatTest$1.run(SimpleDateFormatTest.java:32)trueat java.lang.Thread.run(Thread.java:745)java.lang.NumberFormatException: For input string: ""trueat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)trueat java.lang.Long.parseLong(Long.java:453)trueat java.lang.Long.parseLong(Long.java:483)trueat java.text.DigitList.getLong(DigitList.java:194)trueat java.text.DecimalFormat.parse(DecimalFormat.java:1316)trueat java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1793)trueat java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1455)trueat java.text.DateFormat.parseObject(DateFormat.java:415)trueat java.text.Format.parseObject(Format.java:243)trueat com.smart.tools.SimpleDateFormatTest$1.run(SimpleDateFormatTest.java:32)trueat java.lang.Thread.run(Thread.java:745) 根本原因SimpleDateFormat继承了DateFormat,在DateFormat中定义了一个protected属性的 Calendar类的对象：calendar。只是因为Calendar累的概念复杂，牵扯到时区与本地化等等，Jdk的实现中使用了成员变量来传递参数，这就造成在多线程的时候会出现错误。 在format方法里，有这样一段代码：12private StringBuffer format(Date date, StringBuffer toAppendTo, FieldDelegate delegate) &#123; // Convert input date to time field list calendar.setTime(date)这条语句改变了calendar，稍后，calendar还会用到（在subFormat方法里），而这就是引发问题的根源。想象一下，在一个多线程环境下，有两个线程持有了同一个SimpleDateFormat的实例，分别调用format方法： 线程1调用format方法，改变了calendar这个字段。 中断来了。 线程2开始执行，它也改变了calendar。 又中断了。 线程1回来了，此时，calendar已然不是它所设的值，而是走上了线程2设计的道路。如果多个线程同时争抢calendar对象，则会出现各种问题，时间不对，线程挂死等等。 分析一下format的实现，我们不难发现，用到成员变量calendar，唯一的好处，就是在调用subFormat时，少了一个参数，却带来了这许多的问题。其实，只要在这里用一个局部变量，一路传递下去，所有问题都将迎刃而解。 这个问题背后隐藏着一个更为重要的问题–无状态：无状态方法的好处之一，就是它在各种环境下，都可以安全的调用。衡量一个方法是否是有状态的，就看它是否改动了其它的东西，比如全局变量，比如实例的字段。format方法在运行过程中改动了SimpleDateFormat的calendar字段，所以，它是有状态的。 解决办法 每次需要的时候都创建一个新的实例 使用同步：同步SimpleDateFormat对象 使用common-lang中的api中的FastDateFormat123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.concurrent.CountDownLatch;import org.apache.commons.lang3.time.FastDateFormat;import org.junit.Test;/** * 测试时间处理类的线程安全问题 * @Description * @author gaowenming */public class SimpleDateFormatTest &#123; public static final String PATTEN = "yyyy-MM-dd hh:mm:ss"; public static final SimpleDateFormat sdf = new SimpleDateFormat(PATTEN); public static final CountDownLatch countDownLatch = new CountDownLatch(100); @Test public void testJDKSimpleDateFormat() &#123; //jdk的实现方式，会有线程安全的问题 for (int i = 0; i &lt; 100; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(sdf.parseObject("2013-05-24 06:02:20")); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125; @Test public void testCommonLang() &#123; //CommonLang第三方jar包实现 for (int i = 0; i &lt; 100; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; FastDateFormat fdf = FastDateFormat.getInstance(PATTEN); System.out.println(fdf.format(new Date())); Date date = fdf.parse("2013-05-24 06:02:20"); System.out.println(date); countDownLatch.countDown(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; try &#123; //等待100个线程都执行完 countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"); &#125;&#125;]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>SimpleDateFormat</tag>
      </tags>
  </entry>
</search>
